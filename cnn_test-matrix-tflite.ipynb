{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "#from keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "#import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import lite\n",
    "#from keras.models import Sequential\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, h5_path):\n",
    "    model.save(h5_path)\n",
    "\n",
    "def load_network(h5_path):\n",
    "    ho_model = tf.keras.models.load_model(h5_path)\n",
    "\n",
    "    return ho_model\n",
    "\n",
    "def convert_to_tflite(model, model_path):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    flat_data = converter.convert()\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(flat_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "word={'a':0,'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7,'i':8,'j':9,'k':10,'l':11,'m':12,'n':13,'o':14,'p':15,'q':16,'r':17,'s':18,'t':19,'u':20,'v':21,'w':22,'x':23,'y':24,'z':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1_2():\n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    test_x=[]\n",
    "    test_y=[]\n",
    "    cnt=0\n",
    "    cnt1=0\n",
    "    cnt2=0\n",
    "    cnt3=0\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\cs\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt1+=1\n",
    "                test_x.append(temp_np)\n",
    "                test_y.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x.append(temp_np)\n",
    "                data_y.append(word[i])\n",
    "                \n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\yj\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt2+=1\n",
    "                test_x.append(temp_np)\n",
    "                test_y.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x.append(temp_np)\n",
    "                data_y.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x=np.array(test_x)\n",
    "    test_y=np.array(test_y)\n",
    "    data_x=np.array(data_x)\n",
    "    data_y=np.array(data_y)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y = to_categorical(test_y,num_classes=26)\n",
    "    data_y = to_categorical(data_y,num_classes=26)\n",
    "\n",
    "    return data_x, test_x, data_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1():\n",
    "    # load user one data\n",
    "    data_x_1=[]\n",
    "    data_y_1=[]\n",
    "    test_x_1=[]\n",
    "    test_y_1=[]\n",
    "\n",
    "    cnt=0\n",
    "    cnt1=0\n",
    "\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\cs\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt1+=1\n",
    "                test_x_1.append(temp_np)\n",
    "                test_y_1.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x_1.append(temp_np)\n",
    "                data_y_1.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x_1=np.array(test_x_1)\n",
    "    test_y_1=np.array(test_y_1)\n",
    "    data_x_1=np.array(data_x_1)\n",
    "    data_y_1=np.array(data_y_1)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y_1 = to_categorical(test_y_1,num_classes=26)\n",
    "    data_y_1 = to_categorical(data_y_1,num_classes=26)\n",
    "\n",
    "    return data_x_1, test_x_1, data_y_1, test_y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2():\n",
    "    # load user 2 data\n",
    "    data_x_2=[]\n",
    "    data_y_2=[]\n",
    "    test_x_2=[]\n",
    "    test_y_2=[]\n",
    "\n",
    "    cnt=0\n",
    "    cnt2=0\n",
    "\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\yj\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt2+=1\n",
    "                test_x_2.append(temp_np)\n",
    "                test_y_2.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x_2.append(temp_np)\n",
    "                data_y_2.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x_2=np.array(test_x_2)\n",
    "    test_y_2=np.array(test_y_2)\n",
    "    data_x_2=np.array(data_x_2)\n",
    "    data_y_2=np.array(data_y_2)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y_2 = to_categorical(test_y_2,num_classes=26)\n",
    "    data_y_2 = to_categorical(data_y_2,num_classes=26)\n",
    "\n",
    "    return data_x_2, test_x_2, data_y_2, test_y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainagent:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model_class = model\n",
    "        self.model = None\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def train_model(self, lr, epoch, batch_size, stop, data_x, data_y):\n",
    "        print(f\"lr : {np.log10(lr)}\")\n",
    "\n",
    "        model = self.model_class()\n",
    "        model.init_network()\n",
    "        self.model = model.model\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        callback = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta=0, patience=100, \n",
    "        verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "        total_batch = data_x.shape[0]\n",
    "        decay_steps = int((total_batch/batch_size)/4)\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            lr, decay_steps, t_mul=2.0, m_mul=1.0, alpha=0.0,\n",
    "            name=None\n",
    "        )\n",
    "        opt = optimizers.Adam(learning_rate=lr_schedule)\n",
    "        self.model.compile(loss = \"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "        if stop == True:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2, callbacks=[callback])\n",
    "        else:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "\n",
    "        return history\n",
    "\n",
    "    def search(self, lr, data_x, data_y):\n",
    "\n",
    "        print(\"#============================================================\")\n",
    "        print(\"first search start\")\n",
    "        print(\"#============================================================\")\n",
    "\n",
    "        lr_candidate = np.arange(lr[0], lr[1]+0.1, 0.1)\n",
    "\n",
    "        val_accs = []\n",
    "        for lr in lr_candidate:\n",
    "            history = self.train_model(10**(lr), 16, 32, False, data_x, data_y)\n",
    "            val_acc = history.history[\"val_accuracy\"]\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        temp_val_accs = val_accs[:]\n",
    "        val_accs.sort(key = lambda x: x[-1])\n",
    "        best_val_accs = val_accs[-1]\n",
    "        index = temp_val_accs.index(best_val_accs)\n",
    "        best_lr = lr_candidate[index]\n",
    "\n",
    "        print(\"#============================================================\")\n",
    "        print(\"first search end....\")\n",
    "        print(\"best lr : {}, val_acc : {}\".format(best_lr, best_val_accs[-1]))\n",
    "        print(\"second search start....\")\n",
    "        print(\"#============================================================\")\n",
    "\n",
    "        lr_candidate_L2 = np.arange(best_lr-0.1, best_lr+0.1 + 0.01, 0.01)\n",
    "        val_accs = []\n",
    "        for lr in lr_candidate_L2:\n",
    "            history = self.train_model(10**(lr), 16, 32, False, data_x, data_y)\n",
    "            val_acc = history.history[\"val_accuracy\"]\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        temp_val_accs = val_accs[:]\n",
    "        val_accs.sort(key = lambda x: x[-1])\n",
    "        best_val_accs = val_accs[-1]\n",
    "        index = temp_val_accs.index(best_val_accs)\n",
    "        best_lr = lr_candidate_L2[index]\n",
    "\n",
    "        print(\"#============================================================\")\n",
    "        print(\"second search end....\")\n",
    "        print(\"best lr : {}, val_acc : {}\".format(best_lr, best_val_accs[-1]))\n",
    "        print(\"final train start....\")\n",
    "        print(\"#============================================================\")\n",
    "\n",
    "        history = self.train_model(10**(best_lr), 1024, 32, True, data_x, data_y)\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_1:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def get_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, kernel_size = 5, padding=\"same\", input_shape=data_x[0].shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "        model.add(Conv2D(50, kernel_size = 5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train_model(self, data_x, data_y):\n",
    "    \n",
    "        self.model.fit(data_x, data_y, epochs=10, batch_size=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_2:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(16, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(32, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_3:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(256, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_4:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(128))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_5:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(32, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(64, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(128, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_6:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_7:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_8:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_9:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(16, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(DepthwiseConv2D(kernel_size = 3, padding=\"same\", strides=(1,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size = 1, padding=\"same\", strides=(2,2)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainAndTest(model_class, data_x, data_y, test_x, test_y):\n",
    "\n",
    "    print(\"#=======================================================\")\n",
    "    print(\"# search and train start....\")\n",
    "    print(\"#=======================================================\")\n",
    "    train_agent = trainagent()\n",
    "    train_agent.set_model(model_class)\n",
    "    history = train_agent.search((-5, -2), data_x, data_y)\n",
    "\n",
    "    print(\"#=======================================================\")\n",
    "    print(\"# test start....\")\n",
    "    print(\"#=======================================================\")\n",
    "    model = train_agent.get_model()\n",
    "    result = model.predict(test_x)\n",
    "\n",
    "    pred_y_label = []\n",
    "    test_y_label = []\n",
    "    for pred, truth in zip(result, test_y):\n",
    "        pred_y_label.append(np.argmax(pred))\n",
    "        test_y_label.append(np.argmax(truth))\n",
    "\n",
    "    print(\"test accuracy : {}\".format(accuracy_score(test_y_label, pred_y_label)))\n",
    "\n",
    "\n",
    "    print(\"#=======================================================\")\n",
    "    print(\"# save and load and test start....\")\n",
    "    print(\"#=======================================================\")\n",
    "    class_name = model_class.__name__\n",
    "    save_model(train_agent.get_model(), \"./{}.h5\".format(class_name))\n",
    "\n",
    "    load_model = load_network(\"./{}.h5\".format(class_name))\n",
    "\n",
    "    result = load_model.predict(test_x)\n",
    "\n",
    "    pred_y_label = []\n",
    "    test_y_label = []\n",
    "    for pred, truth in zip(result, test_y):\n",
    "        pred_y_label.append(np.argmax(pred))\n",
    "        test_y_label.append(np.argmax(truth))\n",
    "\n",
    "    print(\"test accuracy : {}\".format(accuracy_score(test_y_label, pred_y_label)))\n",
    "\n",
    "    print(\"#=======================================================\")\n",
    "    print(\"# convert to tflite start\")\n",
    "    print(\"#=======================================================\")\n",
    "    convert_to_tflite(train_agent.get_model(), \"./{}.tflite\".format(class_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_tf_lite(test_x, test_y, tflite_path):\n",
    "    batch_size = test_x.shape[0]\n",
    "\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    output = interpreter.get_output_details()[0]  # Model has single output.\n",
    "    # print(output)\n",
    "    input = interpreter.get_input_details()[0]  # Model has single input.\n",
    "    # print(input)\n",
    "\n",
    "    input_data = tf.convert_to_tensor(test_x, dtype=tf.float32)\n",
    "\n",
    "\n",
    "    result = []\n",
    "    for i in range(batch_size):\n",
    "        test_x_data = input_data[i:i+1,:,:,:]\n",
    "        interpreter.set_tensor(input['index'], test_x_data)\n",
    "        interpreter.invoke()\n",
    "        temp = interpreter.get_tensor(output['index'])\n",
    "        result.append(temp)\n",
    "        \n",
    "\n",
    "    pred_y_label = []\n",
    "    test_y_label = []\n",
    "    for pred, truth in zip(result, test_y):\n",
    "        pred_y_label.append(np.argmax(pred))\n",
    "        test_y_label.append(np.argmax(truth))\n",
    "\n",
    "    print(\"test accuracy : {}\".format(accuracy_score(test_y_label, pred_y_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, test_x, data_y, test_y = load_data_1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#=======================================================\n",
      "# search and train start....\n",
      "#=======================================================\n",
      "#============================================================\n",
      "first search start\n",
      "#============================================================\n",
      "lr : -5.0\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 12s 108ms/step - loss: 3.2264 - accuracy: 0.0837 - val_loss: 3.2909 - val_accuracy: 0.0589\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 11s 111ms/step - loss: 2.5078 - accuracy: 0.3160 - val_loss: 3.0385 - val_accuracy: 0.1534\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 11s 111ms/step - loss: 1.9900 - accuracy: 0.5021 - val_loss: 2.6288 - val_accuracy: 0.2393\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 11s 111ms/step - loss: 1.3097 - accuracy: 0.7429 - val_loss: 2.3832 - val_accuracy: 0.3202\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 1.0991 - accuracy: 0.8000 - val_loss: 2.2960 - val_accuracy: 0.3202\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8124 - accuracy: 0.8675 - val_loss: 2.1221 - val_accuracy: 0.3706\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5216 - accuracy: 0.9408 - val_loss: 2.0350 - val_accuracy: 0.4233\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3870 - accuracy: 0.9736 - val_loss: 2.0215 - val_accuracy: 0.4025\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3360 - accuracy: 0.9813 - val_loss: 2.0119 - val_accuracy: 0.3988\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3306 - accuracy: 0.9779 - val_loss: 2.0120 - val_accuracy: 0.4012\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2483 - accuracy: 0.9880 - val_loss: 1.9639 - val_accuracy: 0.4209\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1620 - accuracy: 0.9979 - val_loss: 1.9140 - val_accuracy: 0.4393\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1184 - accuracy: 0.9997 - val_loss: 1.8819 - val_accuracy: 0.4552\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0929 - accuracy: 1.0000 - val_loss: 1.8705 - val_accuracy: 0.4479\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0789 - accuracy: 1.0000 - val_loss: 1.8738 - val_accuracy: 0.4564\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0713 - accuracy: 1.0000 - val_loss: 1.8612 - val_accuracy: 0.4540\n",
      "lr : -4.9\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 3.0122 - accuracy: 0.1512 - val_loss: 3.1832 - val_accuracy: 0.0920\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.1438 - accuracy: 0.4644 - val_loss: 2.7985 - val_accuracy: 0.1767\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.6426 - accuracy: 0.6064 - val_loss: 2.3792 - val_accuracy: 0.2896\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.0967 - accuracy: 0.7761 - val_loss: 2.1238 - val_accuracy: 0.3706\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.9483 - accuracy: 0.8291 - val_loss: 2.0610 - val_accuracy: 0.3926\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.7434 - accuracy: 0.8601 - val_loss: 1.9376 - val_accuracy: 0.4196\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.5142 - accuracy: 0.9227 - val_loss: 1.8107 - val_accuracy: 0.4663\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3887 - accuracy: 0.9635 - val_loss: 1.8310 - val_accuracy: 0.4773\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3434 - accuracy: 0.9739 - val_loss: 1.7875 - val_accuracy: 0.4834\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3416 - accuracy: 0.9715 - val_loss: 1.7882 - val_accuracy: 0.4699\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2646 - accuracy: 0.9804 - val_loss: 1.7411 - val_accuracy: 0.4933\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1818 - accuracy: 0.9926 - val_loss: 1.7081 - val_accuracy: 0.4982\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1297 - accuracy: 0.9975 - val_loss: 1.6962 - val_accuracy: 0.5239\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1015 - accuracy: 0.9997 - val_loss: 1.6823 - val_accuracy: 0.5178\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0841 - accuracy: 0.9997 - val_loss: 1.6806 - val_accuracy: 0.5141\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0743 - accuracy: 1.0000 - val_loss: 1.6679 - val_accuracy: 0.5166\n",
      "lr : -4.800000000000001\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 101ms/step - loss: 2.7932 - accuracy: 0.2067 - val_loss: 3.2684 - val_accuracy: 0.0564\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.6230 - accuracy: 0.5794 - val_loss: 2.7718 - val_accuracy: 0.1914\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.1271 - accuracy: 0.7270 - val_loss: 2.1705 - val_accuracy: 0.3546\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6513 - accuracy: 0.8890 - val_loss: 1.8061 - val_accuracy: 0.4699\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.5240 - accuracy: 0.9242 - val_loss: 1.7248 - val_accuracy: 0.5166\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3908 - accuracy: 0.9454 - val_loss: 1.6623 - val_accuracy: 0.5350\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2180 - accuracy: 0.9871 - val_loss: 1.6381 - val_accuracy: 0.5288\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1526 - accuracy: 0.9969 - val_loss: 1.6038 - val_accuracy: 0.5497\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1293 - accuracy: 0.9979 - val_loss: 1.6007 - val_accuracy: 0.5423\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1266 - accuracy: 0.9979 - val_loss: 1.6139 - val_accuracy: 0.5546\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0977 - accuracy: 0.9985 - val_loss: 1.5832 - val_accuracy: 0.5546\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0642 - accuracy: 0.9997 - val_loss: 1.5768 - val_accuracy: 0.5448\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0467 - accuracy: 1.0000 - val_loss: 1.5894 - val_accuracy: 0.5546\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0376 - accuracy: 1.0000 - val_loss: 1.5663 - val_accuracy: 0.5656\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 1.5786 - val_accuracy: 0.5607\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.5693\n",
      "lr : -4.700000000000001\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.9899 - accuracy: 0.1512 - val_loss: 3.2467 - val_accuracy: 0.0785\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.7777 - accuracy: 0.5340 - val_loss: 2.9031 - val_accuracy: 0.1301\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.1811 - accuracy: 0.7132 - val_loss: 2.3413 - val_accuracy: 0.3117\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5623 - accuracy: 0.9227 - val_loss: 2.1099 - val_accuracy: 0.3693\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.4195 - accuracy: 0.9546 - val_loss: 2.0515 - val_accuracy: 0.3963\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2918 - accuracy: 0.9715 - val_loss: 1.9114 - val_accuracy: 0.4442\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1379 - accuracy: 0.9972 - val_loss: 1.9013 - val_accuracy: 0.4528\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0944 - accuracy: 0.9997 - val_loss: 1.8904 - val_accuracy: 0.4503\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0805 - accuracy: 1.0000 - val_loss: 1.8903 - val_accuracy: 0.4491\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0792 - accuracy: 1.0000 - val_loss: 1.8948 - val_accuracy: 0.4417\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0608 - accuracy: 1.0000 - val_loss: 1.8992 - val_accuracy: 0.4491\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 1.8705 - val_accuracy: 0.4724\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0312 - accuracy: 1.0000 - val_loss: 1.8735 - val_accuracy: 0.4687\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0258 - accuracy: 1.0000 - val_loss: 1.8543 - val_accuracy: 0.4834\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0222 - accuracy: 1.0000 - val_loss: 1.8560 - val_accuracy: 0.4871\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0200 - accuracy: 1.0000 - val_loss: 1.8558 - val_accuracy: 0.4834\n",
      "lr : -4.600000000000001\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.6202 - accuracy: 0.2702 - val_loss: 3.7699 - val_accuracy: 0.0098\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.2830 - accuracy: 0.6776 - val_loss: 2.7752 - val_accuracy: 0.1436\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8078 - accuracy: 0.8150 - val_loss: 2.1841 - val_accuracy: 0.2908\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.4010 - accuracy: 0.9353 - val_loss: 1.7125 - val_accuracy: 0.4712\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3017 - accuracy: 0.9687 - val_loss: 1.7232 - val_accuracy: 0.4933\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2104 - accuracy: 0.9807 - val_loss: 1.6195 - val_accuracy: 0.5264\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1000 - accuracy: 0.9975 - val_loss: 1.5115 - val_accuracy: 0.5706\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0668 - accuracy: 0.9997 - val_loss: 1.5097 - val_accuracy: 0.5583\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0565 - accuracy: 1.0000 - val_loss: 1.5009 - val_accuracy: 0.5706\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0553 - accuracy: 1.0000 - val_loss: 1.5227 - val_accuracy: 0.5632\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0426 - accuracy: 1.0000 - val_loss: 1.5028 - val_accuracy: 0.5816\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.5091 - val_accuracy: 0.5926\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 1.4917 - val_accuracy: 0.5963\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.4883 - val_accuracy: 0.6000\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.4993 - val_accuracy: 0.5963\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.5951\n",
      "lr : -4.500000000000002\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.7190 - accuracy: 0.2215 - val_loss: 3.8442 - val_accuracy: 0.0761\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.3489 - accuracy: 0.6546 - val_loss: 3.1103 - val_accuracy: 0.1239\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.8217 - accuracy: 0.8129 - val_loss: 2.4505 - val_accuracy: 0.2638\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3126 - accuracy: 0.9678 - val_loss: 1.9991 - val_accuracy: 0.4025\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.2148 - accuracy: 0.9880 - val_loss: 1.8547 - val_accuracy: 0.4528\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1469 - accuracy: 0.9939 - val_loss: 1.8377 - val_accuracy: 0.4638\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0614 - accuracy: 0.9994 - val_loss: 1.8172 - val_accuracy: 0.4859\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 1.8000 - val_accuracy: 0.4920\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0362 - accuracy: 1.0000 - val_loss: 1.8000 - val_accuracy: 0.4896\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0355 - accuracy: 1.0000 - val_loss: 1.8174 - val_accuracy: 0.4994\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.8221 - val_accuracy: 0.5006\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.8147 - val_accuracy: 0.5043\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.8212 - val_accuracy: 0.5018\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 1.8255 - val_accuracy: 0.5104\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.8226 - val_accuracy: 0.5129\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.8258 - val_accuracy: 0.5141\n",
      "lr : -4.400000000000002\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.1151 - accuracy: 0.4209 - val_loss: 3.4457 - val_accuracy: 0.0466\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8818 - accuracy: 0.7788 - val_loss: 2.5426 - val_accuracy: 0.2319\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5740 - accuracy: 0.8748 - val_loss: 1.8446 - val_accuracy: 0.4417\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2517 - accuracy: 0.9696 - val_loss: 1.4864 - val_accuracy: 0.5620\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1803 - accuracy: 0.9844 - val_loss: 1.4721 - val_accuracy: 0.5656\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1298 - accuracy: 0.9893 - val_loss: 1.3667 - val_accuracy: 0.6294\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0560 - accuracy: 0.9991 - val_loss: 1.3425 - val_accuracy: 0.6319\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 1.3462 - val_accuracy: 0.6307\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0324 - accuracy: 1.0000 - val_loss: 1.3404 - val_accuracy: 0.6417\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 1.3722 - val_accuracy: 0.6393\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0242 - accuracy: 1.0000 - val_loss: 1.3448 - val_accuracy: 0.6552\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 1.3473 - val_accuracy: 0.6429\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.3637 - val_accuracy: 0.6577\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.3640 - val_accuracy: 0.6613\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.3712 - val_accuracy: 0.6613\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3708 - val_accuracy: 0.6601\n",
      "lr : -4.3000000000000025\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.3685 - accuracy: 0.3393 - val_loss: 3.7960 - val_accuracy: 0.0724\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8574 - accuracy: 0.7911 - val_loss: 2.5555 - val_accuracy: 0.2221\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.4476 - accuracy: 0.9138 - val_loss: 1.8853 - val_accuracy: 0.4245\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1267 - accuracy: 0.9939 - val_loss: 1.6573 - val_accuracy: 0.5276\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0825 - accuracy: 0.9991 - val_loss: 1.7248 - val_accuracy: 0.4847\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0587 - accuracy: 0.9994 - val_loss: 1.6694 - val_accuracy: 0.5387\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 1.6864 - val_accuracy: 0.5472\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 1.6915 - val_accuracy: 0.5460\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0178 - accuracy: 1.0000 - val_loss: 1.6951 - val_accuracy: 0.5485\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 1.7057 - val_accuracy: 0.5460\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.7086 - val_accuracy: 0.5583\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 1.7167 - val_accuracy: 0.5521\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.7321 - val_accuracy: 0.5620\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.7389 - val_accuracy: 0.5546\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.7421 - val_accuracy: 0.5571\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7489 - val_accuracy: 0.5558\n",
      "lr : -4.200000000000003\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 101ms/step - loss: 2.2577 - accuracy: 0.3543 - val_loss: 3.9020 - val_accuracy: 0.0859\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.7350 - accuracy: 0.8252 - val_loss: 2.5391 - val_accuracy: 0.2393\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3759 - accuracy: 0.9322 - val_loss: 2.0168 - val_accuracy: 0.3914\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.1024 - accuracy: 0.9926 - val_loss: 1.6437 - val_accuracy: 0.5166\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0601 - accuracy: 0.9988 - val_loss: 1.5915 - val_accuracy: 0.5423\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0425 - accuracy: 0.9997 - val_loss: 1.5863 - val_accuracy: 0.5558\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0206 - accuracy: 1.0000 - val_loss: 1.5706 - val_accuracy: 0.5865\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0154 - accuracy: 1.0000 - val_loss: 1.5695 - val_accuracy: 0.5840\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.5710 - val_accuracy: 0.5877\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.6229 - val_accuracy: 0.5742\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.6293 - val_accuracy: 0.5693\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5910 - val_accuracy: 0.6012\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.6040 - val_accuracy: 0.5963\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.6114 - val_accuracy: 0.5975\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.6074 - val_accuracy: 0.5926\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6118 - val_accuracy: 0.6000\n",
      "lr : -4.100000000000003\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 101ms/step - loss: 2.4393 - accuracy: 0.3221 - val_loss: 3.1807 - val_accuracy: 0.1055\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.9291 - accuracy: 0.7690 - val_loss: 2.4789 - val_accuracy: 0.2675\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.5176 - accuracy: 0.8874 - val_loss: 1.9230 - val_accuracy: 0.4172\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.1518 - accuracy: 0.9883 - val_loss: 1.6720 - val_accuracy: 0.5239\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0948 - accuracy: 0.9954 - val_loss: 1.6553 - val_accuracy: 0.5460\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0635 - accuracy: 0.9969 - val_loss: 1.6605 - val_accuracy: 0.5472\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0247 - accuracy: 1.0000 - val_loss: 1.6577 - val_accuracy: 0.5509\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.6668 - val_accuracy: 0.5558\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 1.6736 - val_accuracy: 0.5595\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.5546\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.7123 - val_accuracy: 0.5558\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.7285 - val_accuracy: 0.5558\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 1.7511 - val_accuracy: 0.5730\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7528 - val_accuracy: 0.5669\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.7608 - val_accuracy: 0.5656\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.7722 - val_accuracy: 0.5706\n",
      "lr : -4.0000000000000036\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 101ms/step - loss: 2.1353 - accuracy: 0.4098 - val_loss: 3.5887 - val_accuracy: 0.0724\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6914 - accuracy: 0.8322 - val_loss: 2.4356 - val_accuracy: 0.2638\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3719 - accuracy: 0.9273 - val_loss: 1.7456 - val_accuracy: 0.4601\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0850 - accuracy: 0.9957 - val_loss: 1.5298 - val_accuracy: 0.5325\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0568 - accuracy: 0.9994 - val_loss: 1.6070 - val_accuracy: 0.5301\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0395 - accuracy: 0.9997 - val_loss: 1.5436 - val_accuracy: 0.5730\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0187 - accuracy: 1.0000 - val_loss: 1.5537 - val_accuracy: 0.5681\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.5474 - val_accuracy: 0.5779\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.5730\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.5667 - val_accuracy: 0.5583\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.5933 - val_accuracy: 0.5816\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.5946 - val_accuracy: 0.5755\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.5881 - val_accuracy: 0.5828\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.6061 - val_accuracy: 0.5804\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6120 - val_accuracy: 0.5853\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6141 - val_accuracy: 0.5804\n",
      "lr : -3.900000000000004\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 1.7443 - accuracy: 0.5356 - val_loss: 3.7222 - val_accuracy: 0.0933\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5000 - accuracy: 0.8748 - val_loss: 2.2398 - val_accuracy: 0.3055\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2709 - accuracy: 0.9454 - val_loss: 1.4631 - val_accuracy: 0.5607\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0622 - accuracy: 0.9957 - val_loss: 1.2968 - val_accuracy: 0.6344\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0371 - accuracy: 0.9997 - val_loss: 1.3489 - val_accuracy: 0.6380\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0271 - accuracy: 0.9997 - val_loss: 1.3448 - val_accuracy: 0.6258\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 1.3795 - val_accuracy: 0.6429\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0102 - accuracy: 1.0000 - val_loss: 1.3838 - val_accuracy: 0.6417\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.3824 - val_accuracy: 0.6368\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.3860 - val_accuracy: 0.6503\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.4125 - val_accuracy: 0.6442\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.4245 - val_accuracy: 0.6454\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4435 - val_accuracy: 0.6429\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.4512 - val_accuracy: 0.6454\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.4399 - val_accuracy: 0.6429\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.6380\n",
      "lr : -3.8000000000000043\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.1880 - accuracy: 0.4095 - val_loss: 3.6015 - val_accuracy: 0.0344\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.5658 - accuracy: 0.8607 - val_loss: 2.9228 - val_accuracy: 0.2331\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.2412 - accuracy: 0.9583 - val_loss: 2.0672 - val_accuracy: 0.3914\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.0507 - accuracy: 0.9988 - val_loss: 1.6783 - val_accuracy: 0.5117\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 1.6166 - val_accuracy: 0.5583\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.6407 - val_accuracy: 0.5472\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.6651 - val_accuracy: 0.5485\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.6769 - val_accuracy: 0.5485\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 1.6775 - val_accuracy: 0.5497\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.6986 - val_accuracy: 0.5558\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.7280 - val_accuracy: 0.5521\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.5497\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7537 - val_accuracy: 0.5485\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.7655 - val_accuracy: 0.5583\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.7821 - val_accuracy: 0.5497\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7748 - val_accuracy: 0.5607\n",
      "lr : -3.7000000000000046\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.7080 - accuracy: 0.3310 - val_loss: 3.5785 - val_accuracy: 0.0736\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.0236 - accuracy: 0.7577 - val_loss: 3.0453 - val_accuracy: 0.1791\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.5444 - accuracy: 0.8819 - val_loss: 4.0298 - val_accuracy: 0.1337\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1397 - accuracy: 0.9871 - val_loss: 2.2937 - val_accuracy: 0.3423\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0829 - accuracy: 0.9951 - val_loss: 2.0921 - val_accuracy: 0.3890\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0529 - accuracy: 0.9982 - val_loss: 1.9480 - val_accuracy: 0.4123\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.6356 - val_accuracy: 0.5337\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.5817 - val_accuracy: 0.5521\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.5454 - val_accuracy: 0.5767\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.6006 - val_accuracy: 0.5706\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.6170 - val_accuracy: 0.5656\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6334 - val_accuracy: 0.5669\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.6396 - val_accuracy: 0.5681\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.6453 - val_accuracy: 0.5816\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6436 - val_accuracy: 0.5865\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6452 - val_accuracy: 0.5914\n",
      "lr : -3.600000000000005\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.8382 - accuracy: 0.4043 - val_loss: 4.1242 - val_accuracy: 0.1534\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.7375 - accuracy: 0.8224 - val_loss: 2.5924 - val_accuracy: 0.2344\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3796 - accuracy: 0.9190 - val_loss: 1.8555 - val_accuracy: 0.4687\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1031 - accuracy: 0.9896 - val_loss: 1.4682 - val_accuracy: 0.6123\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0600 - accuracy: 0.9975 - val_loss: 1.4430 - val_accuracy: 0.6160\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0417 - accuracy: 0.9988 - val_loss: 1.4499 - val_accuracy: 0.6294\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0172 - accuracy: 1.0000 - val_loss: 1.4662 - val_accuracy: 0.6258\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.4760 - val_accuracy: 0.6319\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.4919 - val_accuracy: 0.6221\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.4741 - val_accuracy: 0.6331\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.5012 - val_accuracy: 0.6466\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5110 - val_accuracy: 0.6319\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5326 - val_accuracy: 0.6368\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5292 - val_accuracy: 0.6368\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5520 - val_accuracy: 0.6393\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5586 - val_accuracy: 0.6331\n",
      "lr : -3.5000000000000053\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.1652 - accuracy: 0.5018 - val_loss: 4.5306 - val_accuracy: 0.0393\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5464 - accuracy: 0.8598 - val_loss: 2.5946 - val_accuracy: 0.2859\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2758 - accuracy: 0.9396 - val_loss: 1.8677 - val_accuracy: 0.4270\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0590 - accuracy: 0.9951 - val_loss: 1.4362 - val_accuracy: 0.5914\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 1.3979 - val_accuracy: 0.6417\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 1.4017 - val_accuracy: 0.6491\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3617 - val_accuracy: 0.6687\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.3571 - val_accuracy: 0.6761\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.3717 - val_accuracy: 0.6724\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3796 - val_accuracy: 0.6748\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.3824 - val_accuracy: 0.6675\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.4028 - val_accuracy: 0.6822\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.3973 - val_accuracy: 0.6859\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.4236 - val_accuracy: 0.6810\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.4189 - val_accuracy: 0.6822\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4222 - val_accuracy: 0.6871\n",
      "lr : -3.4000000000000057\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 3.3859 - accuracy: 0.3586 - val_loss: 8.5421 - val_accuracy: 0.0687\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.7954 - accuracy: 0.8113 - val_loss: 5.7346 - val_accuracy: 0.1276\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3677 - accuracy: 0.9310 - val_loss: 3.1032 - val_accuracy: 0.2098\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0757 - accuracy: 0.9972 - val_loss: 1.9881 - val_accuracy: 0.3693\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0472 - accuracy: 0.9994 - val_loss: 1.7471 - val_accuracy: 0.4969\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0308 - accuracy: 1.0000 - val_loss: 1.7202 - val_accuracy: 0.5141\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.5644\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 1.6088 - val_accuracy: 0.5718\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.5965 - val_accuracy: 0.5828\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.6191 - val_accuracy: 0.5877\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.6307 - val_accuracy: 0.5865\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.6560 - val_accuracy: 0.5865\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6537 - val_accuracy: 0.5865\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6738 - val_accuracy: 0.5816\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6734 - val_accuracy: 0.5840\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6808 - val_accuracy: 0.5939\n",
      "lr : -3.300000000000006\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 3.4845 - accuracy: 0.4110 - val_loss: 3.6924 - val_accuracy: 0.0712\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.7231 - accuracy: 0.8150 - val_loss: 2.2785 - val_accuracy: 0.3325\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3705 - accuracy: 0.9230 - val_loss: 1.7641 - val_accuracy: 0.4908\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0728 - accuracy: 0.9933 - val_loss: 1.5246 - val_accuracy: 0.5595\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0396 - accuracy: 0.9997 - val_loss: 1.5346 - val_accuracy: 0.5877\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0278 - accuracy: 0.9994 - val_loss: 1.5414 - val_accuracy: 0.5926\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.4655 - val_accuracy: 0.6147\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0090 - accuracy: 1.0000 - val_loss: 1.4586 - val_accuracy: 0.6282\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.4576 - val_accuracy: 0.6282\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.4913 - val_accuracy: 0.6147\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.5113 - val_accuracy: 0.6209\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4966 - val_accuracy: 0.6270\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.5294 - val_accuracy: 0.6245\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.5269 - val_accuracy: 0.6294\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5480 - val_accuracy: 0.6233\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.5427 - val_accuracy: 0.6380\n",
      "lr : -3.2000000000000064\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 3.2564 - accuracy: 0.4525 - val_loss: 11.4065 - val_accuracy: 0.0405\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.5628 - accuracy: 0.8558 - val_loss: 7.3165 - val_accuracy: 0.0589\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.2735 - accuracy: 0.9451 - val_loss: 3.3217 - val_accuracy: 0.1890\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0508 - accuracy: 0.9969 - val_loss: 1.6184 - val_accuracy: 0.5190\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0256 - accuracy: 1.0000 - val_loss: 1.5003 - val_accuracy: 0.5840\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0180 - accuracy: 1.0000 - val_loss: 1.4937 - val_accuracy: 0.5914\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.5064 - val_accuracy: 0.6184\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5147 - val_accuracy: 0.6172\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.5205 - val_accuracy: 0.6209\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5372 - val_accuracy: 0.6196\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.5438 - val_accuracy: 0.6258\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5615 - val_accuracy: 0.6294\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5721 - val_accuracy: 0.6221\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5870 - val_accuracy: 0.6282\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5984 - val_accuracy: 0.6196\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6047 - val_accuracy: 0.6270\n",
      "lr : -3.1000000000000068\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 4.0613 - accuracy: 0.4549 - val_loss: 3.2817 - val_accuracy: 0.0429\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.5891 - accuracy: 0.8475 - val_loss: 2.3792 - val_accuracy: 0.3092\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2986 - accuracy: 0.9227 - val_loss: 1.6031 - val_accuracy: 0.5387\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0457 - accuracy: 0.9960 - val_loss: 1.3648 - val_accuracy: 0.6528\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0205 - accuracy: 0.9994 - val_loss: 1.5198 - val_accuracy: 0.6294\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.5244 - val_accuracy: 0.6429\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.5257 - val_accuracy: 0.6393\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5411 - val_accuracy: 0.6356\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5414 - val_accuracy: 0.6380\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.5548 - val_accuracy: 0.6442\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5842 - val_accuracy: 0.6393\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6131 - val_accuracy: 0.6356\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6186 - val_accuracy: 0.6417\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6407 - val_accuracy: 0.6380\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6446 - val_accuracy: 0.6344\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.6464 - val_accuracy: 0.6356\n",
      "lr : -3.000000000000007\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 7.3776 - accuracy: 0.2893 - val_loss: 4.3763 - val_accuracy: 0.1055\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8696 - accuracy: 0.7764 - val_loss: 2.7411 - val_accuracy: 0.2466\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3957 - accuracy: 0.9129 - val_loss: 2.0119 - val_accuracy: 0.4319\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0699 - accuracy: 0.9933 - val_loss: 1.5572 - val_accuracy: 0.6037\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0332 - accuracy: 0.9988 - val_loss: 1.5910 - val_accuracy: 0.6000\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0213 - accuracy: 1.0000 - val_loss: 1.6188 - val_accuracy: 0.6233\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.6076 - val_accuracy: 0.6172\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.6293 - val_accuracy: 0.6160\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.6402 - val_accuracy: 0.6160\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.6616 - val_accuracy: 0.6196\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.6635 - val_accuracy: 0.6282\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6831 - val_accuracy: 0.6282\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.7103 - val_accuracy: 0.6258\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.7141 - val_accuracy: 0.6221\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.7216 - val_accuracy: 0.6221\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.7307 - val_accuracy: 0.6270\n",
      "lr : -2.9000000000000075\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 7.6809 - accuracy: 0.3371 - val_loss: 3.5747 - val_accuracy: 0.0552\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6490 - accuracy: 0.8307 - val_loss: 2.5137 - val_accuracy: 0.2294\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.2467 - accuracy: 0.9512 - val_loss: 1.6592 - val_accuracy: 0.4994\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0385 - accuracy: 0.9979 - val_loss: 1.4104 - val_accuracy: 0.6221\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0211 - accuracy: 0.9997 - val_loss: 1.5124 - val_accuracy: 0.5951\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0148 - accuracy: 0.9997 - val_loss: 1.6020 - val_accuracy: 0.5939\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.5578 - val_accuracy: 0.6221\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5593 - val_accuracy: 0.6294\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.5757 - val_accuracy: 0.6344\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5936 - val_accuracy: 0.6258\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.6288 - val_accuracy: 0.6331\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.6303 - val_accuracy: 0.6270\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.6403 - val_accuracy: 0.6245\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6557 - val_accuracy: 0.6331\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6657 - val_accuracy: 0.6368\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.6708 - val_accuracy: 0.6344\n",
      "lr : -2.800000000000008\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 102ms/step - loss: 8.3880 - accuracy: 0.3988 - val_loss: 3.3309 - val_accuracy: 0.0380\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.6502 - accuracy: 0.8248 - val_loss: 2.0196 - val_accuracy: 0.3681\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.3184 - accuracy: 0.9258 - val_loss: 1.6281 - val_accuracy: 0.5472\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0547 - accuracy: 0.9942 - val_loss: 1.5040 - val_accuracy: 0.6245\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0258 - accuracy: 0.9994 - val_loss: 1.6058 - val_accuracy: 0.6233\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.5389 - val_accuracy: 0.6405\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5113 - val_accuracy: 0.6491\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.6577\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.5277 - val_accuracy: 0.6552\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.5529 - val_accuracy: 0.6540\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.5836 - val_accuracy: 0.6491\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5889 - val_accuracy: 0.6564\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6104 - val_accuracy: 0.6528\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.6190 - val_accuracy: 0.6503\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.6261 - val_accuracy: 0.6503\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6319 - val_accuracy: 0.6552\n",
      "lr : -2.700000000000008\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 102ms/step - loss: 10.7827 - accuracy: 0.2144 - val_loss: 3.3064 - val_accuracy: 0.0650\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 1.1145 - accuracy: 0.7012 - val_loss: 2.7482 - val_accuracy: 0.2135\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.5423 - accuracy: 0.8543 - val_loss: 2.1275 - val_accuracy: 0.3939\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.1152 - accuracy: 0.9853 - val_loss: 1.6610 - val_accuracy: 0.5350\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0530 - accuracy: 0.9975 - val_loss: 1.7813 - val_accuracy: 0.5571\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0356 - accuracy: 0.9975 - val_loss: 1.8497 - val_accuracy: 0.5558\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.8664 - val_accuracy: 0.5693\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.8908 - val_accuracy: 0.5656\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.8874 - val_accuracy: 0.5742\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.9313 - val_accuracy: 0.5853\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.9745 - val_accuracy: 0.5804\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9902 - val_accuracy: 0.5828\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.5890\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.0199 - val_accuracy: 0.5902\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.0351 - val_accuracy: 0.5902\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.0434 - val_accuracy: 0.5890\n",
      "lr : -2.6000000000000085\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 101ms/step - loss: 14.4625 - accuracy: 0.1015 - val_loss: 3.2890 - val_accuracy: 0.0442\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.3939 - accuracy: 0.3126 - val_loss: 3.2858 - val_accuracy: 0.0896\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.4328 - accuracy: 0.5727 - val_loss: 2.3506 - val_accuracy: 0.3546\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3766 - accuracy: 0.9110 - val_loss: 2.6409 - val_accuracy: 0.3595\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.2140 - accuracy: 0.9675 - val_loss: 3.4356 - val_accuracy: 0.3227\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1354 - accuracy: 0.9773 - val_loss: 2.2919 - val_accuracy: 0.4368\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0328 - accuracy: 0.9982 - val_loss: 2.4427 - val_accuracy: 0.4393\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0147 - accuracy: 0.9994 - val_loss: 2.3647 - val_accuracy: 0.4442\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0113 - accuracy: 0.9997 - val_loss: 2.3373 - val_accuracy: 0.4540\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0112 - accuracy: 0.9997 - val_loss: 2.4226 - val_accuracy: 0.4699\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.5925 - val_accuracy: 0.4344\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.5945 - val_accuracy: 0.4479\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6076 - val_accuracy: 0.4466\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.6094 - val_accuracy: 0.4577\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.6284 - val_accuracy: 0.4601\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6481 - val_accuracy: 0.4577\n",
      "lr : -2.500000000000009\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 16.5622 - accuracy: 0.2169 - val_loss: 3.3422 - val_accuracy: 0.0393\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.5093 - accuracy: 0.5681 - val_loss: 3.0691 - val_accuracy: 0.1497\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.9361 - accuracy: 0.7282 - val_loss: 2.1984 - val_accuracy: 0.4110\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3011 - accuracy: 0.9209 - val_loss: 1.6157 - val_accuracy: 0.5693\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1709 - accuracy: 0.9647 - val_loss: 1.6982 - val_accuracy: 0.5730\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1535 - accuracy: 0.9601 - val_loss: 2.7505 - val_accuracy: 0.4540\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0389 - accuracy: 0.9929 - val_loss: 2.0362 - val_accuracy: 0.5779\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0126 - accuracy: 0.9994 - val_loss: 1.9381 - val_accuracy: 0.6098\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0092 - accuracy: 0.9997 - val_loss: 1.9524 - val_accuracy: 0.6160\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0088 - accuracy: 0.9997 - val_loss: 1.9687 - val_accuracy: 0.6123\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0069 - accuracy: 0.9997 - val_loss: 2.0533 - val_accuracy: 0.6258\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.0763 - val_accuracy: 0.6245\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.1462 - val_accuracy: 0.6061\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.1284 - val_accuracy: 0.6209\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.1566 - val_accuracy: 0.6233\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.1651 - val_accuracy: 0.6221\n",
      "lr : -2.4000000000000092\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 24.2961 - accuracy: 0.0641 - val_loss: 3.9766 - val_accuracy: 0.0405\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.9718 - accuracy: 0.0917 - val_loss: 3.2620 - val_accuracy: 0.0491\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.7961 - accuracy: 0.1199 - val_loss: 3.1139 - val_accuracy: 0.0957\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.5286 - accuracy: 0.1543 - val_loss: 2.9044 - val_accuracy: 0.1178\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.4774 - accuracy: 0.1948 - val_loss: 2.8379 - val_accuracy: 0.1227\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.3903 - accuracy: 0.1966 - val_loss: 2.9009 - val_accuracy: 0.1436\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.2509 - accuracy: 0.2509 - val_loss: 2.6648 - val_accuracy: 0.2000\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.1418 - accuracy: 0.2742 - val_loss: 2.8056 - val_accuracy: 0.1681\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.0627 - accuracy: 0.2957 - val_loss: 2.7671 - val_accuracy: 0.1742\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.0429 - accuracy: 0.2991 - val_loss: 2.6538 - val_accuracy: 0.1902\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.9723 - accuracy: 0.2963 - val_loss: 3.4525 - val_accuracy: 0.1301\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.9249 - accuracy: 0.3264 - val_loss: 2.6942 - val_accuracy: 0.1804\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.7838 - accuracy: 0.3509 - val_loss: 3.8012 - val_accuracy: 0.1092\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.5971 - accuracy: 0.4064 - val_loss: 3.6286 - val_accuracy: 0.1804\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.4641 - accuracy: 0.4531 - val_loss: 3.4166 - val_accuracy: 0.2172\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.3710 - accuracy: 0.5144 - val_loss: 3.1921 - val_accuracy: 0.2380\n",
      "lr : -2.3000000000000096\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 25.2347 - accuracy: 0.0408 - val_loss: 3.4428 - val_accuracy: 0.0442\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2796 - accuracy: 0.0417 - val_loss: 3.2580 - val_accuracy: 0.0405\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2590 - accuracy: 0.0316 - val_loss: 3.2574 - val_accuracy: 0.0393\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.2585 - accuracy: 0.0380 - val_loss: 3.2573 - val_accuracy: 0.0405\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2580 - accuracy: 0.0377 - val_loss: 3.2575 - val_accuracy: 0.0393\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.2589 - accuracy: 0.0304 - val_loss: 3.2572 - val_accuracy: 0.0393\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2587 - accuracy: 0.0331 - val_loss: 3.2570 - val_accuracy: 0.0393\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2581 - accuracy: 0.0310 - val_loss: 3.2569 - val_accuracy: 0.0393\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2578 - accuracy: 0.0350 - val_loss: 3.2569 - val_accuracy: 0.0393\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2583 - accuracy: 0.0359 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2591 - accuracy: 0.0365 - val_loss: 3.2565 - val_accuracy: 0.0393\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2590 - accuracy: 0.0301 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2587 - accuracy: 0.0344 - val_loss: 3.2567 - val_accuracy: 0.0393\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.2585 - accuracy: 0.0304 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.2583 - accuracy: 0.0340 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.2581 - accuracy: 0.0291 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "lr : -2.20000000000001\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 31.8621 - accuracy: 0.0592 - val_loss: 4.0759 - val_accuracy: 0.0712\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 2.9407 - accuracy: 0.1328 - val_loss: 3.1801 - val_accuracy: 0.1227\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 2.6366 - accuracy: 0.2003 - val_loss: 2.9471 - val_accuracy: 0.1227\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 1.9835 - accuracy: 0.3660 - val_loss: 3.1350 - val_accuracy: 0.1681\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 1.4882 - accuracy: 0.5515 - val_loss: 4.7152 - val_accuracy: 0.1902\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 1.1944 - accuracy: 0.6089 - val_loss: 3.2144 - val_accuracy: 0.2834\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.6382 - accuracy: 0.7899 - val_loss: 3.6242 - val_accuracy: 0.3166\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.2784 - accuracy: 0.9261 - val_loss: 3.2596 - val_accuracy: 0.3656\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.1632 - accuracy: 0.9647 - val_loss: 3.3581 - val_accuracy: 0.3718\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.1903 - accuracy: 0.9482 - val_loss: 4.2119 - val_accuracy: 0.2933\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.2737 - accuracy: 0.9224 - val_loss: 6.5254 - val_accuracy: 0.2613\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.3084 - accuracy: 0.9049 - val_loss: 5.4482 - val_accuracy: 0.2663\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.3277 - accuracy: 0.9021 - val_loss: 7.4766 - val_accuracy: 0.2331\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.1514 - accuracy: 0.9540 - val_loss: 6.6472 - val_accuracy: 0.2908\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0653 - accuracy: 0.9810 - val_loss: 5.7177 - val_accuracy: 0.3595\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0376 - accuracy: 0.9917 - val_loss: 5.4905 - val_accuracy: 0.3681\n",
      "lr : -2.1000000000000103\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 36.7200 - accuracy: 0.0463 - val_loss: 3.2581 - val_accuracy: 0.0405\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2648 - accuracy: 0.0316 - val_loss: 3.2574 - val_accuracy: 0.0380\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2582 - accuracy: 0.0356 - val_loss: 3.2566 - val_accuracy: 0.0405\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2588 - accuracy: 0.0362 - val_loss: 3.2564 - val_accuracy: 0.0405\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 3.2569 - accuracy: 0.0380 - val_loss: 3.2565 - val_accuracy: 0.0393\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2594 - accuracy: 0.0377 - val_loss: 3.2563 - val_accuracy: 0.0393\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2595 - accuracy: 0.0310 - val_loss: 3.2560 - val_accuracy: 0.0393\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 11s 105ms/step - loss: 3.2582 - accuracy: 0.0350 - val_loss: 3.2561 - val_accuracy: 0.0393\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 3.2576 - accuracy: 0.0383 - val_loss: 3.2561 - val_accuracy: 0.0393\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2584 - accuracy: 0.0377 - val_loss: 3.2560 - val_accuracy: 0.0405\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2602 - accuracy: 0.0331 - val_loss: 3.2562 - val_accuracy: 0.0405\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 3.2593 - accuracy: 0.0319 - val_loss: 3.2567 - val_accuracy: 0.0405\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2595 - accuracy: 0.0334 - val_loss: 3.2566 - val_accuracy: 0.0380\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 3.2591 - accuracy: 0.0340 - val_loss: 3.2567 - val_accuracy: 0.0380\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2587 - accuracy: 0.0347 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 3.2584 - accuracy: 0.0356 - val_loss: 3.2566 - val_accuracy: 0.0393\n",
      "lr : -2.0000000000000107\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 40.9541 - accuracy: 0.0672 - val_loss: 3.2587 - val_accuracy: 0.0380\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 2.7083 - accuracy: 0.2083 - val_loss: 3.3481 - val_accuracy: 0.0638\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 2.1885 - accuracy: 0.3552 - val_loss: 3.2169 - val_accuracy: 0.1669\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 1.5331 - accuracy: 0.5236 - val_loss: 2.5294 - val_accuracy: 0.2503\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 1.2405 - accuracy: 0.6117 - val_loss: 3.0386 - val_accuracy: 0.2528\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 1.0455 - accuracy: 0.6586 - val_loss: 2.4431 - val_accuracy: 0.3890\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.6661 - accuracy: 0.7853 - val_loss: 2.2742 - val_accuracy: 0.4307\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.3740 - accuracy: 0.8926 - val_loss: 3.4460 - val_accuracy: 0.3607\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.2633 - accuracy: 0.9322 - val_loss: 2.8847 - val_accuracy: 0.4245\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.3110 - accuracy: 0.9089 - val_loss: 3.0013 - val_accuracy: 0.4172\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.4923 - accuracy: 0.8429 - val_loss: 6.2175 - val_accuracy: 0.2748\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.3909 - accuracy: 0.8767 - val_loss: 3.8696 - val_accuracy: 0.4233\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.2262 - accuracy: 0.9393 - val_loss: 7.7573 - val_accuracy: 0.2380\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.1687 - accuracy: 0.9515 - val_loss: 3.9357 - val_accuracy: 0.4196\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0961 - accuracy: 0.9706 - val_loss: 4.6639 - val_accuracy: 0.3939\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 5.1888 - val_accuracy: 0.3890\n",
      "#============================================================\n",
      "first search end....\n",
      "best lr : -3.5000000000000053, val_acc : 0.6871165633201599\n",
      "second search start....\n",
      "#============================================================\n",
      "lr : -3.6000000000000054\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 3.3699 - accuracy: 0.1942 - val_loss: 3.0547 - val_accuracy: 0.1239\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 1.4811 - accuracy: 0.6702 - val_loss: 2.6328 - val_accuracy: 0.2098\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.8528 - accuracy: 0.8255 - val_loss: 2.1395 - val_accuracy: 0.3497\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.2762 - accuracy: 0.9752 - val_loss: 1.8275 - val_accuracy: 0.4822\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1715 - accuracy: 0.9920 - val_loss: 1.8324 - val_accuracy: 0.4724\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.1048 - accuracy: 0.9926 - val_loss: 1.7686 - val_accuracy: 0.5227\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0360 - accuracy: 1.0000 - val_loss: 1.7496 - val_accuracy: 0.5350\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 1.7626 - val_accuracy: 0.5350\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0193 - accuracy: 1.0000 - val_loss: 1.7657 - val_accuracy: 0.5337\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.7871 - val_accuracy: 0.5399\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.8088 - val_accuracy: 0.5509\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 1.8373 - val_accuracy: 0.5558\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.8514 - val_accuracy: 0.5509\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.8800 - val_accuracy: 0.5374\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.9067 - val_accuracy: 0.5423\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.9112 - val_accuracy: 0.5509\n",
      "lr : -3.5900000000000056\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 2.5046 - accuracy: 0.3966 - val_loss: 3.6704 - val_accuracy: 0.0982\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.6457 - accuracy: 0.8534 - val_loss: 2.4802 - val_accuracy: 0.2577\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3064 - accuracy: 0.9494 - val_loss: 1.8410 - val_accuracy: 0.4785\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0628 - accuracy: 0.9975 - val_loss: 1.6144 - val_accuracy: 0.5546\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0361 - accuracy: 0.9997 - val_loss: 1.6193 - val_accuracy: 0.5509\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 1.6376 - val_accuracy: 0.5546\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.6495 - val_accuracy: 0.5853\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.6557 - val_accuracy: 0.5669\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.6642 - val_accuracy: 0.5669\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.6756 - val_accuracy: 0.5583\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.7050 - val_accuracy: 0.5595\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.7053 - val_accuracy: 0.5730\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.7343 - val_accuracy: 0.5632\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.7350 - val_accuracy: 0.5755\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.7381 - val_accuracy: 0.5730\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.7478 - val_accuracy: 0.5742\n",
      "lr : -3.580000000000006\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 2.9341 - accuracy: 0.2684 - val_loss: 4.3555 - val_accuracy: 0.0405\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.8923 - accuracy: 0.7954 - val_loss: 2.9260 - val_accuracy: 0.1607\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.4368 - accuracy: 0.9160 - val_loss: 2.3143 - val_accuracy: 0.2687\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.1101 - accuracy: 0.9914 - val_loss: 1.6762 - val_accuracy: 0.5031\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0595 - accuracy: 0.9985 - val_loss: 1.6434 - val_accuracy: 0.5117\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0368 - accuracy: 0.9997 - val_loss: 1.6354 - val_accuracy: 0.5472\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0164 - accuracy: 1.0000 - val_loss: 1.6234 - val_accuracy: 0.5521\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 1.6121 - val_accuracy: 0.5583\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.6143 - val_accuracy: 0.5656\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0104 - accuracy: 1.0000 - val_loss: 1.6719 - val_accuracy: 0.5571\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.6527 - val_accuracy: 0.5571\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6485 - val_accuracy: 0.5755\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.6880 - val_accuracy: 0.5706\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.6838 - val_accuracy: 0.5742\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6857 - val_accuracy: 0.5755\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6933 - val_accuracy: 0.5791\n",
      "lr : -3.570000000000006\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 2.5831 - accuracy: 0.4340 - val_loss: 3.4221 - val_accuracy: 0.0380\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.6792 - accuracy: 0.8258 - val_loss: 2.6723 - val_accuracy: 0.2196\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3582 - accuracy: 0.9264 - val_loss: 1.7093 - val_accuracy: 0.4822\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0738 - accuracy: 0.9945 - val_loss: 1.3715 - val_accuracy: 0.6098\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0410 - accuracy: 0.9997 - val_loss: 1.3779 - val_accuracy: 0.6221\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0277 - accuracy: 0.9991 - val_loss: 1.4392 - val_accuracy: 0.6221\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 1.4222 - val_accuracy: 0.6393\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.4572 - val_accuracy: 0.6429\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.4605 - val_accuracy: 0.6368\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4628 - val_accuracy: 0.6491\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4866 - val_accuracy: 0.6466\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5073 - val_accuracy: 0.6491\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.5337 - val_accuracy: 0.6356\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.4996 - val_accuracy: 0.6540\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5192 - val_accuracy: 0.6466\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5433 - val_accuracy: 0.6479\n",
      "lr : -3.5600000000000063\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.3439 - accuracy: 0.4359 - val_loss: 3.6280 - val_accuracy: 0.1043\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6108 - accuracy: 0.8497 - val_loss: 2.6548 - val_accuracy: 0.1890\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3216 - accuracy: 0.9319 - val_loss: 1.5770 - val_accuracy: 0.5104\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0754 - accuracy: 0.9957 - val_loss: 1.3583 - val_accuracy: 0.6110\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0413 - accuracy: 1.0000 - val_loss: 1.3880 - val_accuracy: 0.6282\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0297 - accuracy: 1.0000 - val_loss: 1.3974 - val_accuracy: 0.6184\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.4035 - val_accuracy: 0.6233\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0106 - accuracy: 1.0000 - val_loss: 1.4296 - val_accuracy: 0.6258\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4396 - val_accuracy: 0.6258\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.4485 - val_accuracy: 0.6331\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.4698 - val_accuracy: 0.6258\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4588 - val_accuracy: 0.6417\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5061 - val_accuracy: 0.6245\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5003 - val_accuracy: 0.6380\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5155 - val_accuracy: 0.6344\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5211 - val_accuracy: 0.6380\n",
      "lr : -3.5500000000000065\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.7707 - accuracy: 0.3531 - val_loss: 3.4855 - val_accuracy: 0.0356\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.7503 - accuracy: 0.8206 - val_loss: 3.0851 - val_accuracy: 0.1178\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.4046 - accuracy: 0.9138 - val_loss: 1.9661 - val_accuracy: 0.4307\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1046 - accuracy: 0.9896 - val_loss: 1.5213 - val_accuracy: 0.5620\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0576 - accuracy: 0.9994 - val_loss: 1.4444 - val_accuracy: 0.6012\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0395 - accuracy: 0.9997 - val_loss: 1.4100 - val_accuracy: 0.6258\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.4504 - val_accuracy: 0.6147\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 1.4505 - val_accuracy: 0.6172\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.4539 - val_accuracy: 0.6135\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.4638 - val_accuracy: 0.6209\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.4667 - val_accuracy: 0.6282\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 1.5039 - val_accuracy: 0.6258\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.4982 - val_accuracy: 0.6307\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5096 - val_accuracy: 0.6196\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.5040 - val_accuracy: 0.6258\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5144 - val_accuracy: 0.6135\n",
      "lr : -3.5400000000000067\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 2.7302 - accuracy: 0.4482 - val_loss: 3.7544 - val_accuracy: 0.0442\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.5862 - accuracy: 0.8534 - val_loss: 2.6300 - val_accuracy: 0.2515\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3429 - accuracy: 0.9212 - val_loss: 1.8813 - val_accuracy: 0.4380\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0795 - accuracy: 0.9936 - val_loss: 1.3611 - val_accuracy: 0.6012\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0465 - accuracy: 0.9991 - val_loss: 1.3681 - val_accuracy: 0.6147\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0333 - accuracy: 0.9997 - val_loss: 1.3459 - val_accuracy: 0.6209\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3145 - val_accuracy: 0.6454\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.3098 - val_accuracy: 0.6491\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.3081 - val_accuracy: 0.6417\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.3167 - val_accuracy: 0.6466\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3444 - val_accuracy: 0.6331\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.3275 - val_accuracy: 0.6577\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3471 - val_accuracy: 0.6503\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 1.3764 - val_accuracy: 0.6405\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.3530 - val_accuracy: 0.6503\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.3675 - val_accuracy: 0.6564\n",
      "lr : -3.530000000000007\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 2.4204 - accuracy: 0.4558 - val_loss: 4.4106 - val_accuracy: 0.0761\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.5930 - accuracy: 0.8500 - val_loss: 2.2699 - val_accuracy: 0.3067\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.2920 - accuracy: 0.9429 - val_loss: 1.3467 - val_accuracy: 0.6074\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0754 - accuracy: 0.9933 - val_loss: 1.2502 - val_accuracy: 0.6368\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0437 - accuracy: 0.9994 - val_loss: 1.2813 - val_accuracy: 0.6503\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0288 - accuracy: 0.9994 - val_loss: 1.3444 - val_accuracy: 0.6294\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.3194 - val_accuracy: 0.6626\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.3249 - val_accuracy: 0.6601\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3380 - val_accuracy: 0.6528\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 1.3684 - val_accuracy: 0.6344\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3739 - val_accuracy: 0.6515\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3519 - val_accuracy: 0.6552\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.3847 - val_accuracy: 0.6540\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3855 - val_accuracy: 0.6528\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.3849 - val_accuracy: 0.6577\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.3866 - val_accuracy: 0.6577\n",
      "lr : -3.520000000000007\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 102ms/step - loss: 2.9604 - accuracy: 0.4433 - val_loss: 6.2012 - val_accuracy: 0.0920\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.6567 - accuracy: 0.8411 - val_loss: 3.6454 - val_accuracy: 0.2061\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.3585 - accuracy: 0.9190 - val_loss: 2.1053 - val_accuracy: 0.4319\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0923 - accuracy: 0.9926 - val_loss: 1.4807 - val_accuracy: 0.5791\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0508 - accuracy: 0.9985 - val_loss: 1.4595 - val_accuracy: 0.6172\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0333 - accuracy: 0.9991 - val_loss: 1.4081 - val_accuracy: 0.6393\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.4568 - val_accuracy: 0.6282\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.4703 - val_accuracy: 0.6270\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4779 - val_accuracy: 0.6294\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.5227 - val_accuracy: 0.6319\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.5444 - val_accuracy: 0.6172\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 1.5746 - val_accuracy: 0.6233\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.5734 - val_accuracy: 0.6344\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 1.5920 - val_accuracy: 0.6380\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.6042 - val_accuracy: 0.6368\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6184 - val_accuracy: 0.6356\n",
      "lr : -3.5100000000000073\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 3.5385 - accuracy: 0.3000 - val_loss: 3.9883 - val_accuracy: 0.0699\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.1027 - accuracy: 0.7362 - val_loss: 3.8248 - val_accuracy: 0.1387\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6143 - accuracy: 0.8650 - val_loss: 3.5562 - val_accuracy: 0.1865\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.2228 - accuracy: 0.9702 - val_loss: 2.0349 - val_accuracy: 0.4172\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1512 - accuracy: 0.9871 - val_loss: 1.9159 - val_accuracy: 0.4650\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0984 - accuracy: 0.9939 - val_loss: 1.7424 - val_accuracy: 0.5350\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0368 - accuracy: 0.9997 - val_loss: 1.4229 - val_accuracy: 0.6025\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0235 - accuracy: 1.0000 - val_loss: 1.3586 - val_accuracy: 0.6393\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 1.3557 - val_accuracy: 0.6454\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 1.4470 - val_accuracy: 0.5963\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 1.4168 - val_accuracy: 0.6307\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.4140 - val_accuracy: 0.6368\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4575 - val_accuracy: 0.6282\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.4594 - val_accuracy: 0.6405\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.4646 - val_accuracy: 0.6442\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.4648 - val_accuracy: 0.6491\n",
      "lr : -3.5000000000000075\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 2.7591 - accuracy: 0.4583 - val_loss: 8.6212 - val_accuracy: 0.0405\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.6098 - accuracy: 0.8405 - val_loss: 4.3393 - val_accuracy: 0.1166\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.3295 - accuracy: 0.9248 - val_loss: 1.8169 - val_accuracy: 0.4822\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0633 - accuracy: 0.9954 - val_loss: 1.4640 - val_accuracy: 0.6025\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0321 - accuracy: 0.9997 - val_loss: 1.5707 - val_accuracy: 0.5840\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.5093 - val_accuracy: 0.6196\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.5464 - val_accuracy: 0.6110\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.5458 - val_accuracy: 0.6172\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 1.5513 - val_accuracy: 0.6123\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5804 - val_accuracy: 0.6258\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.5921 - val_accuracy: 0.6160\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.6091 - val_accuracy: 0.6135\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.6283 - val_accuracy: 0.6184\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.6326 - val_accuracy: 0.6233\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.6458 - val_accuracy: 0.6110\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6564 - val_accuracy: 0.6147\n",
      "lr : -3.4900000000000078\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 3.0467 - accuracy: 0.3512 - val_loss: 3.6013 - val_accuracy: 0.1509\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8619 - accuracy: 0.7942 - val_loss: 2.5356 - val_accuracy: 0.2344\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.4535 - accuracy: 0.9009 - val_loss: 1.9436 - val_accuracy: 0.4196\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1028 - accuracy: 0.9939 - val_loss: 1.6985 - val_accuracy: 0.5202\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0588 - accuracy: 0.9991 - val_loss: 1.7073 - val_accuracy: 0.5313\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.7185 - val_accuracy: 0.5276\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.7430 - val_accuracy: 0.5337\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.7443 - val_accuracy: 0.5362\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 1.7513 - val_accuracy: 0.5362\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.7621 - val_accuracy: 0.5521\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 97ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.7930 - val_accuracy: 0.5521\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 1.8295 - val_accuracy: 0.5337\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.8407 - val_accuracy: 0.5485\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8587 - val_accuracy: 0.5460\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.8738 - val_accuracy: 0.5546\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.8942 - val_accuracy: 0.5509\n",
      "lr : -3.480000000000008\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 106ms/step - loss: 3.2310 - accuracy: 0.3178 - val_loss: 4.4960 - val_accuracy: 0.0650\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.7568 - accuracy: 0.8209 - val_loss: 3.5903 - val_accuracy: 0.1411\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.3885 - accuracy: 0.9227 - val_loss: 2.4984 - val_accuracy: 0.3166\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 11s 105ms/step - loss: 0.0923 - accuracy: 0.9942 - val_loss: 1.5906 - val_accuracy: 0.5558\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0566 - accuracy: 0.9991 - val_loss: 1.5694 - val_accuracy: 0.5779\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0378 - accuracy: 0.9997 - val_loss: 1.5331 - val_accuracy: 0.6000\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0171 - accuracy: 1.0000 - val_loss: 1.5229 - val_accuracy: 0.6086\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.5289 - val_accuracy: 0.6061\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 1.5218 - val_accuracy: 0.6160\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.6172\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.5515 - val_accuracy: 0.6209\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.5769 - val_accuracy: 0.6184\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.5852 - val_accuracy: 0.6270\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.5797 - val_accuracy: 0.6307\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5967 - val_accuracy: 0.6307\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.5944 - val_accuracy: 0.6282\n",
      "lr : -3.470000000000008\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 106ms/step - loss: 2.7581 - accuracy: 0.4666 - val_loss: 5.5510 - val_accuracy: 0.0552\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.6584 - accuracy: 0.8344 - val_loss: 3.3268 - val_accuracy: 0.1534\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.3614 - accuracy: 0.9187 - val_loss: 1.6150 - val_accuracy: 0.5043\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0853 - accuracy: 0.9911 - val_loss: 1.3435 - val_accuracy: 0.6368\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0435 - accuracy: 0.9991 - val_loss: 1.4458 - val_accuracy: 0.6184\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0277 - accuracy: 0.9997 - val_loss: 1.4513 - val_accuracy: 0.6491\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 1.4416 - val_accuracy: 0.6528\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.4642 - val_accuracy: 0.6479\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 1.4695 - val_accuracy: 0.6491\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.4961 - val_accuracy: 0.6479\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.5107 - val_accuracy: 0.6479\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.5051 - val_accuracy: 0.6552\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.5472 - val_accuracy: 0.6503\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 1.5543 - val_accuracy: 0.6589\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.5613 - val_accuracy: 0.6540\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.5748 - val_accuracy: 0.6540\n",
      "lr : -3.4600000000000084\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 2.4516 - accuracy: 0.4693 - val_loss: 6.2511 - val_accuracy: 0.0663\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.6701 - accuracy: 0.8236 - val_loss: 2.6014 - val_accuracy: 0.3018\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.4158 - accuracy: 0.8951 - val_loss: 1.6834 - val_accuracy: 0.5153\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.1164 - accuracy: 0.9874 - val_loss: 1.4308 - val_accuracy: 0.6123\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0699 - accuracy: 0.9966 - val_loss: 1.7027 - val_accuracy: 0.5865\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0493 - accuracy: 0.9972 - val_loss: 1.4127 - val_accuracy: 0.6319\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.2992 - val_accuracy: 0.6724\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.3039 - val_accuracy: 0.6785\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.6675\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 1.3245 - val_accuracy: 0.6650\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.3457 - val_accuracy: 0.6822\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.3810 - val_accuracy: 0.6785\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.3840 - val_accuracy: 0.6724\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 1.3947 - val_accuracy: 0.6675\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.4052 - val_accuracy: 0.6699\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.4016 - val_accuracy: 0.6724\n",
      "lr : -3.4500000000000086\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 2.5947 - accuracy: 0.4310 - val_loss: 4.5036 - val_accuracy: 0.0650\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.5511 - accuracy: 0.8644 - val_loss: 3.0389 - val_accuracy: 0.1804\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.2722 - accuracy: 0.9479 - val_loss: 1.9038 - val_accuracy: 0.4282\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0528 - accuracy: 0.9988 - val_loss: 1.4293 - val_accuracy: 0.6012\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0333 - accuracy: 1.0000 - val_loss: 1.3914 - val_accuracy: 0.6086\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 1.3955 - val_accuracy: 0.6331\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0117 - accuracy: 1.0000 - val_loss: 1.3665 - val_accuracy: 0.6429\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 1.3575 - val_accuracy: 0.6528\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 1.3490 - val_accuracy: 0.6613\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.3555 - val_accuracy: 0.6663\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3790 - val_accuracy: 0.6577\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3895 - val_accuracy: 0.6724\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.3939 - val_accuracy: 0.6712\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.3871 - val_accuracy: 0.6748\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 1.3941 - val_accuracy: 0.6712\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.4029 - val_accuracy: 0.6736\n",
      "lr : -3.440000000000009\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 4.0944 - accuracy: 0.1761 - val_loss: 3.2660 - val_accuracy: 0.0491\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 1.5577 - accuracy: 0.6595 - val_loss: 3.0361 - val_accuracy: 0.1877\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.7356 - accuracy: 0.8463 - val_loss: 2.2453 - val_accuracy: 0.3252\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.1583 - accuracy: 0.9862 - val_loss: 1.7218 - val_accuracy: 0.4982\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0929 - accuracy: 0.9982 - val_loss: 1.7593 - val_accuracy: 0.4626\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0584 - accuracy: 0.9991 - val_loss: 1.7261 - val_accuracy: 0.5153\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0237 - accuracy: 1.0000 - val_loss: 1.7111 - val_accuracy: 0.5264\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.7151 - val_accuracy: 0.5264\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0145 - accuracy: 1.0000 - val_loss: 1.7186 - val_accuracy: 0.5325\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.7212 - val_accuracy: 0.5301\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.7670 - val_accuracy: 0.5264\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.7830 - val_accuracy: 0.5387\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 1.7828 - val_accuracy: 0.5374\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8091 - val_accuracy: 0.5448\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 1.8087 - val_accuracy: 0.5423\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.8250 - val_accuracy: 0.5448\n",
      "lr : -3.430000000000009\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 104ms/step - loss: 3.2978 - accuracy: 0.3650 - val_loss: 3.3874 - val_accuracy: 0.0356\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.7606 - accuracy: 0.8163 - val_loss: 2.7717 - val_accuracy: 0.2147\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.3793 - accuracy: 0.9233 - val_loss: 2.3484 - val_accuracy: 0.3497\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0713 - accuracy: 0.9939 - val_loss: 1.6707 - val_accuracy: 0.5215\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0416 - accuracy: 0.9994 - val_loss: 1.5459 - val_accuracy: 0.5669\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0252 - accuracy: 1.0000 - val_loss: 1.5857 - val_accuracy: 0.5816\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.5717 - val_accuracy: 0.5767\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.5686 - val_accuracy: 0.5926\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 1.5703 - val_accuracy: 0.5877\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.5951 - val_accuracy: 0.5804\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.6494 - val_accuracy: 0.5718\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.6342 - val_accuracy: 0.5840\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6536 - val_accuracy: 0.5828\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 102ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6631 - val_accuracy: 0.5865\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 1.6704 - val_accuracy: 0.5914\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 103ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6808 - val_accuracy: 0.5877\n",
      "lr : -3.4200000000000093\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 103ms/step - loss: 2.3834 - accuracy: 0.4890 - val_loss: 6.4521 - val_accuracy: 0.1117\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.5300 - accuracy: 0.8558 - val_loss: 2.8684 - val_accuracy: 0.2393\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.2400 - accuracy: 0.9485 - val_loss: 1.6774 - val_accuracy: 0.5043\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0465 - accuracy: 0.9979 - val_loss: 1.3792 - val_accuracy: 0.6184\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0252 - accuracy: 0.9997 - val_loss: 1.4129 - val_accuracy: 0.6233\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0174 - accuracy: 1.0000 - val_loss: 1.4561 - val_accuracy: 0.6344\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 1.4930 - val_accuracy: 0.6209\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.5081 - val_accuracy: 0.6233\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.5210 - val_accuracy: 0.6196\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.5334 - val_accuracy: 0.6258\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.6184\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.5815 - val_accuracy: 0.6294\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5943 - val_accuracy: 0.6331\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.6423 - val_accuracy: 0.6245\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 1.6284 - val_accuracy: 0.6368\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.6520 - val_accuracy: 0.6294\n",
      "lr : -3.4100000000000095\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 3.1852 - accuracy: 0.3344 - val_loss: 3.6860 - val_accuracy: 0.0736\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.7513 - accuracy: 0.8193 - val_loss: 3.5077 - val_accuracy: 0.1288\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.3681 - accuracy: 0.9242 - val_loss: 2.1801 - val_accuracy: 0.3730\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0852 - accuracy: 0.9954 - val_loss: 1.6419 - val_accuracy: 0.5166\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0515 - accuracy: 0.9997 - val_loss: 1.6464 - val_accuracy: 0.5399\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0386 - accuracy: 0.9994 - val_loss: 1.6062 - val_accuracy: 0.5718\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0177 - accuracy: 1.0000 - val_loss: 1.5637 - val_accuracy: 0.5730\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0129 - accuracy: 1.0000 - val_loss: 1.5656 - val_accuracy: 0.5828\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 1.5653 - val_accuracy: 0.5816\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0109 - accuracy: 1.0000 - val_loss: 1.6060 - val_accuracy: 0.5755\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.6048 - val_accuracy: 0.5779\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 1.6065 - val_accuracy: 0.5902\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.6227 - val_accuracy: 0.5951\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.6249 - val_accuracy: 0.5865\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.6218 - val_accuracy: 0.5902\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 1.6290 - val_accuracy: 0.5926\n",
      "lr : -3.4000000000000097\n",
      "Epoch 1/16\n",
      "102/102 [==============================] - 11s 99ms/step - loss: 3.3646 - accuracy: 0.3963 - val_loss: 3.2651 - val_accuracy: 0.0957\n",
      "Epoch 2/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.8419 - accuracy: 0.7972 - val_loss: 2.2731 - val_accuracy: 0.3215\n",
      "Epoch 3/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.4786 - accuracy: 0.8874 - val_loss: 2.4208 - val_accuracy: 0.3288\n",
      "Epoch 4/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.1278 - accuracy: 0.9871 - val_loss: 1.8834 - val_accuracy: 0.4356\n",
      "Epoch 5/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0692 - accuracy: 0.9982 - val_loss: 1.7653 - val_accuracy: 0.4871\n",
      "Epoch 6/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0494 - accuracy: 0.9988 - val_loss: 1.7001 - val_accuracy: 0.5190\n",
      "Epoch 7/16\n",
      "102/102 [==============================] - 10s 101ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 1.5862 - val_accuracy: 0.5436\n",
      "Epoch 8/16\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 1.5928 - val_accuracy: 0.5571\n",
      "Epoch 9/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.5980 - val_accuracy: 0.5534\n",
      "Epoch 10/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.6315 - val_accuracy: 0.5521\n",
      "Epoch 11/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 1.6650 - val_accuracy: 0.5497\n",
      "Epoch 12/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.6593 - val_accuracy: 0.5583\n",
      "Epoch 13/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 1.6845 - val_accuracy: 0.5546\n",
      "Epoch 14/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 1.7007 - val_accuracy: 0.5558\n",
      "Epoch 15/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 1.6974 - val_accuracy: 0.5607\n",
      "Epoch 16/16\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 1.6949 - val_accuracy: 0.5632\n",
      "#============================================================\n",
      "second search end....\n",
      "best lr : -3.4500000000000086, val_acc : 0.6736196279525757\n",
      "final train start....\n",
      "#============================================================\n",
      "lr : -3.4500000000000086\n",
      "Epoch 1/1024\n",
      "102/102 [==============================] - 11s 100ms/step - loss: 3.0517 - accuracy: 0.3742 - val_loss: 3.2650 - val_accuracy: 0.0368\n",
      "Epoch 2/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.8910 - accuracy: 0.7748 - val_loss: 2.3213 - val_accuracy: 0.3239\n",
      "Epoch 3/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.4532 - accuracy: 0.9031 - val_loss: 1.4921 - val_accuracy: 0.5779\n",
      "Epoch 4/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.1052 - accuracy: 0.9929 - val_loss: 1.3284 - val_accuracy: 0.6270\n",
      "Epoch 5/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0601 - accuracy: 0.9991 - val_loss: 1.3384 - val_accuracy: 0.6123\n",
      "Epoch 6/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0370 - accuracy: 0.9997 - val_loss: 1.3732 - val_accuracy: 0.6160\n",
      "Epoch 7/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 1.3899 - val_accuracy: 0.6196\n",
      "Epoch 8/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.3878 - val_accuracy: 0.6196\n",
      "Epoch 9/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 1.3852 - val_accuracy: 0.6245\n",
      "Epoch 10/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.4072 - val_accuracy: 0.6184\n",
      "Epoch 11/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.4255 - val_accuracy: 0.6160\n",
      "Epoch 12/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 1.4423 - val_accuracy: 0.6147\n",
      "Epoch 13/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.4482 - val_accuracy: 0.6221\n",
      "Epoch 14/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.5115 - val_accuracy: 0.6209\n",
      "Epoch 15/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 1.4931 - val_accuracy: 0.6307\n",
      "Epoch 16/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.5110 - val_accuracy: 0.6270\n",
      "Epoch 17/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.5157 - val_accuracy: 0.6245\n",
      "Epoch 18/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5175 - val_accuracy: 0.6245\n",
      "Epoch 19/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5215 - val_accuracy: 0.6258\n",
      "Epoch 20/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.5423 - val_accuracy: 0.6270\n",
      "Epoch 21/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.5472 - val_accuracy: 0.6344\n",
      "Epoch 22/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 8.2400e-04 - accuracy: 1.0000 - val_loss: 1.6220 - val_accuracy: 0.6393\n",
      "Epoch 23/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 6.4976e-04 - accuracy: 1.0000 - val_loss: 1.6173 - val_accuracy: 0.6331\n",
      "Epoch 24/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 5.1076e-04 - accuracy: 1.0000 - val_loss: 1.6300 - val_accuracy: 0.6393\n",
      "Epoch 25/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 4.2648e-04 - accuracy: 1.0000 - val_loss: 1.6644 - val_accuracy: 0.6417\n",
      "Epoch 26/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.6128e-04 - accuracy: 1.0000 - val_loss: 1.6686 - val_accuracy: 0.6429\n",
      "Epoch 27/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 3.1416e-04 - accuracy: 1.0000 - val_loss: 1.6906 - val_accuracy: 0.6442\n",
      "Epoch 28/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.8130e-04 - accuracy: 1.0000 - val_loss: 1.6767 - val_accuracy: 0.6380\n",
      "Epoch 29/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.5367e-04 - accuracy: 1.0000 - val_loss: 1.7099 - val_accuracy: 0.6380\n",
      "Epoch 30/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.3228e-04 - accuracy: 1.0000 - val_loss: 1.6987 - val_accuracy: 0.6417\n",
      "Epoch 31/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.1352e-04 - accuracy: 1.0000 - val_loss: 1.7192 - val_accuracy: 0.6393\n",
      "Epoch 32/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.0417e-04 - accuracy: 1.0000 - val_loss: 1.7286 - val_accuracy: 0.6417\n",
      "Epoch 33/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.9232e-04 - accuracy: 1.0000 - val_loss: 1.7291 - val_accuracy: 0.6405\n",
      "Epoch 34/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.8895e-04 - accuracy: 1.0000 - val_loss: 1.7323 - val_accuracy: 0.6393\n",
      "Epoch 35/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.7689e-04 - accuracy: 1.0000 - val_loss: 1.7393 - val_accuracy: 0.6417\n",
      "Epoch 36/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.7974e-04 - accuracy: 1.0000 - val_loss: 1.7358 - val_accuracy: 0.6405\n",
      "Epoch 37/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.7377e-04 - accuracy: 1.0000 - val_loss: 1.7325 - val_accuracy: 0.6393\n",
      "Epoch 38/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.7410e-04 - accuracy: 1.0000 - val_loss: 1.7330 - val_accuracy: 0.6393\n",
      "Epoch 39/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.7306e-04 - accuracy: 1.0000 - val_loss: 1.7460 - val_accuracy: 0.6331\n",
      "Epoch 40/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.5720e-04 - accuracy: 1.0000 - val_loss: 1.7689 - val_accuracy: 0.6368\n",
      "Epoch 41/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.2274e-04 - accuracy: 1.0000 - val_loss: 1.7989 - val_accuracy: 0.6368\n",
      "Epoch 42/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.8570e-05 - accuracy: 1.0000 - val_loss: 1.8336 - val_accuracy: 0.6356\n",
      "Epoch 43/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 8.0809e-05 - accuracy: 1.0000 - val_loss: 1.8347 - val_accuracy: 0.6356\n",
      "Epoch 44/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 6.6159e-05 - accuracy: 1.0000 - val_loss: 1.8563 - val_accuracy: 0.6356\n",
      "Epoch 45/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 5.6509e-05 - accuracy: 1.0000 - val_loss: 1.8801 - val_accuracy: 0.6344\n",
      "Epoch 46/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 5.0021e-05 - accuracy: 1.0000 - val_loss: 1.9006 - val_accuracy: 0.6307\n",
      "Epoch 47/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 4.3957e-05 - accuracy: 1.0000 - val_loss: 1.9354 - val_accuracy: 0.6319\n",
      "Epoch 48/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.8256e-05 - accuracy: 1.0000 - val_loss: 1.9111 - val_accuracy: 0.6368\n",
      "Epoch 49/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.4569e-05 - accuracy: 1.0000 - val_loss: 1.9364 - val_accuracy: 0.6356\n",
      "Epoch 50/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.9772e-05 - accuracy: 1.0000 - val_loss: 1.9590 - val_accuracy: 0.6368\n",
      "Epoch 51/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.7029e-05 - accuracy: 1.0000 - val_loss: 1.9623 - val_accuracy: 0.6356\n",
      "Epoch 52/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.3807e-05 - accuracy: 1.0000 - val_loss: 1.9764 - val_accuracy: 0.6331\n",
      "Epoch 53/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 2.2028e-05 - accuracy: 1.0000 - val_loss: 2.0022 - val_accuracy: 0.6344\n",
      "Epoch 54/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.9923e-05 - accuracy: 1.0000 - val_loss: 2.0011 - val_accuracy: 0.6380\n",
      "Epoch 55/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.9168e-05 - accuracy: 1.0000 - val_loss: 2.0175 - val_accuracy: 0.6344\n",
      "Epoch 56/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.8284e-05 - accuracy: 1.0000 - val_loss: 2.0173 - val_accuracy: 0.6417\n",
      "Epoch 57/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.6222e-05 - accuracy: 1.0000 - val_loss: 2.0456 - val_accuracy: 0.6319\n",
      "Epoch 58/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.5722e-05 - accuracy: 1.0000 - val_loss: 2.0450 - val_accuracy: 0.6356\n",
      "Epoch 59/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.4338e-05 - accuracy: 1.0000 - val_loss: 2.0587 - val_accuracy: 0.6319\n",
      "Epoch 60/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.3559e-05 - accuracy: 1.0000 - val_loss: 2.0518 - val_accuracy: 0.6331\n",
      "Epoch 61/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.2623e-05 - accuracy: 1.0000 - val_loss: 2.0642 - val_accuracy: 0.6294\n",
      "Epoch 62/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.2357e-05 - accuracy: 1.0000 - val_loss: 2.0722 - val_accuracy: 0.6331\n",
      "Epoch 63/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.1813e-05 - accuracy: 1.0000 - val_loss: 2.0783 - val_accuracy: 0.6344\n",
      "Epoch 64/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.1159e-05 - accuracy: 1.0000 - val_loss: 2.0758 - val_accuracy: 0.6319\n",
      "Epoch 65/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.0985e-05 - accuracy: 1.0000 - val_loss: 2.0870 - val_accuracy: 0.6307\n",
      "Epoch 66/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.0962e-05 - accuracy: 1.0000 - val_loss: 2.0876 - val_accuracy: 0.6356\n",
      "Epoch 67/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.0885e-05 - accuracy: 1.0000 - val_loss: 2.0945 - val_accuracy: 0.6294\n",
      "Epoch 68/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.0061e-05 - accuracy: 1.0000 - val_loss: 2.0968 - val_accuracy: 0.6344\n",
      "Epoch 69/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.7142e-06 - accuracy: 1.0000 - val_loss: 2.1019 - val_accuracy: 0.6307\n",
      "Epoch 70/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.7994e-06 - accuracy: 1.0000 - val_loss: 2.1026 - val_accuracy: 0.6294\n",
      "Epoch 71/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.7514e-06 - accuracy: 1.0000 - val_loss: 2.1040 - val_accuracy: 0.6307\n",
      "Epoch 72/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.7150e-06 - accuracy: 1.0000 - val_loss: 2.1092 - val_accuracy: 0.6294\n",
      "Epoch 73/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.3816e-06 - accuracy: 1.0000 - val_loss: 2.1102 - val_accuracy: 0.6319\n",
      "Epoch 74/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.4634e-06 - accuracy: 1.0000 - val_loss: 2.1101 - val_accuracy: 0.6307\n",
      "Epoch 75/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.3775e-06 - accuracy: 1.0000 - val_loss: 2.1120 - val_accuracy: 0.6319\n",
      "Epoch 76/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.5851e-06 - accuracy: 1.0000 - val_loss: 2.1125 - val_accuracy: 0.6319\n",
      "Epoch 77/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.3193e-06 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.6307\n",
      "Epoch 78/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 9.6291e-06 - accuracy: 1.0000 - val_loss: 2.1753 - val_accuracy: 0.6356\n",
      "Epoch 79/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 8.5219e-06 - accuracy: 1.0000 - val_loss: 2.1493 - val_accuracy: 0.6282\n",
      "Epoch 80/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 6.8571e-06 - accuracy: 1.0000 - val_loss: 2.1806 - val_accuracy: 0.6307\n",
      "Epoch 81/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 5.8069e-06 - accuracy: 1.0000 - val_loss: 2.2258 - val_accuracy: 0.6245\n",
      "Epoch 82/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 4.9825e-06 - accuracy: 1.0000 - val_loss: 2.2130 - val_accuracy: 0.6319\n",
      "Epoch 83/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 4.3093e-06 - accuracy: 1.0000 - val_loss: 2.2615 - val_accuracy: 0.6270\n",
      "Epoch 84/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.7821e-06 - accuracy: 1.0000 - val_loss: 2.2807 - val_accuracy: 0.6258\n",
      "Epoch 85/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 3.3945e-06 - accuracy: 1.0000 - val_loss: 2.2902 - val_accuracy: 0.6245\n",
      "Epoch 86/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.9347e-06 - accuracy: 1.0000 - val_loss: 2.3173 - val_accuracy: 0.6270\n",
      "Epoch 87/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.9072e-06 - accuracy: 1.0000 - val_loss: 2.3173 - val_accuracy: 0.6245\n",
      "Epoch 88/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 2.5100e-06 - accuracy: 1.0000 - val_loss: 2.3421 - val_accuracy: 0.6270\n",
      "Epoch 89/1024\n",
      "102/102 [==============================] - 10s 100ms/step - loss: 2.2349e-06 - accuracy: 1.0000 - val_loss: 2.3642 - val_accuracy: 0.6270\n",
      "Epoch 90/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.9593e-06 - accuracy: 1.0000 - val_loss: 2.3962 - val_accuracy: 0.6258\n",
      "Epoch 91/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.8499e-06 - accuracy: 1.0000 - val_loss: 2.4139 - val_accuracy: 0.6245\n",
      "Epoch 92/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.6615e-06 - accuracy: 1.0000 - val_loss: 2.4093 - val_accuracy: 0.6270\n",
      "Epoch 93/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.5030e-06 - accuracy: 1.0000 - val_loss: 2.4441 - val_accuracy: 0.6258\n",
      "Epoch 94/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.9596e-06 - accuracy: 1.0000 - val_loss: 2.4322 - val_accuracy: 0.6294\n",
      "Epoch 95/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.2909e-06 - accuracy: 1.0000 - val_loss: 2.4670 - val_accuracy: 0.6245\n",
      "Epoch 96/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 1.2395e-06 - accuracy: 1.0000 - val_loss: 2.4876 - val_accuracy: 0.6221\n",
      "Epoch 97/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.1540e-06 - accuracy: 1.0000 - val_loss: 2.4941 - val_accuracy: 0.6233\n",
      "Epoch 98/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 1.0425e-06 - accuracy: 1.0000 - val_loss: 2.5014 - val_accuracy: 0.6221\n",
      "Epoch 99/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.7912e-07 - accuracy: 1.0000 - val_loss: 2.5189 - val_accuracy: 0.6209\n",
      "Epoch 100/1024\n",
      "102/102 [==============================] - 10s 98ms/step - loss: 9.1787e-07 - accuracy: 1.0000 - val_loss: 2.5264 - val_accuracy: 0.6196\n",
      "Epoch 101/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 8.2924e-07 - accuracy: 1.0000 - val_loss: 2.5326 - val_accuracy: 0.6184\n",
      "Epoch 102/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 8.0550e-07 - accuracy: 1.0000 - val_loss: 2.5480 - val_accuracy: 0.6209\n",
      "Epoch 103/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 7.6363e-07 - accuracy: 1.0000 - val_loss: 2.5536 - val_accuracy: 0.6221\n",
      "Epoch 104/1024\n",
      "102/102 [==============================] - 10s 99ms/step - loss: 7.3617e-07 - accuracy: 1.0000 - val_loss: 2.5559 - val_accuracy: 0.6233\n",
      "#=======================================================\n",
      "# test start....\n",
      "#=======================================================\n",
      "#=======================================================\n",
      "# save and load and test start....\n",
      "#=======================================================\n",
      "#=======================================================\n",
      "# convert to tflite start\n",
      "#=======================================================\n",
      "INFO:tensorflow:Assets written to: C:\\Users\\JAEYON~1\\AppData\\Local\\Temp\\tmp_oib7ozv\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
     ]
    }
   ],
   "source": [
    "TrainAndTest(Net_9, data_x, data_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tflite  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy : 0.823076923076923\n"
     ]
    }
   ],
   "source": [
    "test_tf_lite(test_x, test_y, \"./Net2.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
