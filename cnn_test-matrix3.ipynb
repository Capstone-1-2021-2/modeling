{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import libarary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "#from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "import tensorflow as tf\n",
    "#from keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "#import np_utils\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow import lite\n",
    "#from keras.models import Sequential\n",
    "#import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, h5_path):\n",
    "    model.save(h5_path)\n",
    "\n",
    "def load_network(h5_path):\n",
    "    ho_model = tf.keras.models.load_model(h5_path)\n",
    "\n",
    "    return ho_model\n",
    "\n",
    "def convert_to_tflite(model, model_path):\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    flat_data = converter.convert()\n",
    "    with open(model_path, 'wb') as f:\n",
    "        f.write(flat_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "word={'a':0,'b':1,'c':2,'d':3,'e':4,'f':5,'g':6,'h':7,'i':8,'j':9,'k':10,'l':11,'m':12,'n':13,'o':14,'p':15,'q':16,'r':17,'s':18,'t':19,'u':20,'v':21,'w':22,'x':23,'y':24,'z':25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1_2():\n",
    "    data_x=[]\n",
    "    data_y=[]\n",
    "    test_x=[]\n",
    "    test_y=[]\n",
    "    cnt=0\n",
    "    cnt1=0\n",
    "    cnt2=0\n",
    "    cnt3=0\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\cs\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt1+=1\n",
    "                test_x.append(temp_np)\n",
    "                test_y.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x.append(temp_np)\n",
    "                data_y.append(word[i])\n",
    "                \n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\yj\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt2+=1\n",
    "                test_x.append(temp_np)\n",
    "                test_y.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x.append(temp_np)\n",
    "                data_y.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x=np.array(test_x)\n",
    "    test_y=np.array(test_y)\n",
    "    data_x=np.array(data_x)\n",
    "    data_y=np.array(data_y)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y = to_categorical(test_y,num_classes=26)\n",
    "    data_y = to_categorical(data_y,num_classes=26)\n",
    "\n",
    "    return data_x, test_x, data_y, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_1():\n",
    "    # load user one data\n",
    "    data_x_1=[]\n",
    "    data_y_1=[]\n",
    "    test_x_1=[]\n",
    "    test_y_1=[]\n",
    "\n",
    "    cnt=0\n",
    "    cnt1=0\n",
    "\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\cs\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt1+=1\n",
    "                test_x_1.append(temp_np)\n",
    "                test_y_1.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x_1.append(temp_np)\n",
    "                data_y_1.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x_1=np.array(test_x_1)\n",
    "    test_y_1=np.array(test_y_1)\n",
    "    data_x_1=np.array(data_x_1)\n",
    "    data_y_1=np.array(data_y_1)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y_1 = to_categorical(test_y_1,num_classes=26)\n",
    "    data_y_1 = to_categorical(data_y_1,num_classes=26)\n",
    "\n",
    "    return data_x_1, test_x_1, data_y_1, test_y_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_2():\n",
    "    # load user 2 data\n",
    "    data_x_2=[]\n",
    "    data_y_2=[]\n",
    "    test_x_2=[]\n",
    "    test_y_2=[]\n",
    "\n",
    "    cnt=0\n",
    "    cnt2=0\n",
    "\n",
    "    for j in range(0,100):\n",
    "        for i in ['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']:\n",
    "            #print(i+str(j)+\".txt\")\n",
    "        \n",
    "        \n",
    "                \n",
    "            \n",
    "            \n",
    "            try:\n",
    "                f = open(\"matrixWav2\\\\yj\\\\\"+i+\"\\\\\"+i+str(j)+\".txt\")\n",
    "                line = f.readline()\n",
    "                temp=line.split(\",\")\n",
    "                f.close()\n",
    "            except:\n",
    "                cnt+=1\n",
    "                continue\n",
    "            \n",
    "            \n",
    "            temp_np=np.array(list(map(float, temp)))\n",
    "            #temp_np=(temp_np - temp_np.min(axis=0)) / (temp_np.max(axis=0) - temp_np.min(axis=0)) #min-max scaling\n",
    "            temp_np=temp_np.reshape(1248,24,1) #not resize\n",
    "            \n",
    "            \n",
    "            if j in range(80,100):\n",
    "                cnt2+=1\n",
    "                test_x_2.append(temp_np)\n",
    "                test_y_2.append(word[i])\n",
    "            \n",
    "            else:\n",
    "                data_x_2.append(temp_np)\n",
    "                data_y_2.append(word[i])            \n",
    "\n",
    "                \n",
    "    test_x_2=np.array(test_x_2)\n",
    "    test_y_2=np.array(test_y_2)\n",
    "    data_x_2=np.array(data_x_2)\n",
    "    data_y_2=np.array(data_y_2)\n",
    "\n",
    "\n",
    "    #type casting\n",
    "\n",
    "\n",
    "    test_y_2 = to_categorical(test_y_2,num_classes=26)\n",
    "    data_y_2 = to_categorical(data_y_2,num_classes=26)\n",
    "\n",
    "    return data_x_2, test_x_2, data_y_2, test_y_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_1:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def get_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(20, kernel_size = 5, padding=\"same\", input_shape=data_x[0].shape))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "        model.add(Conv2D(50, kernel_size = 5, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(500))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train_model(self, data_x, data_y):\n",
    "    \n",
    "        self.model.fit(data_x, data_y, epochs=10, batch_size=130)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_2:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(8, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(16, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(32, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(BatchNormalization(axis=3))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train_model(self, lr, epoch, batch_size, stop, data_x, data_y):\n",
    "        print(f\"lr : {lr}\")\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        callback = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta=0, patience=100, \n",
    "        verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "        total_batch = data_x.shape[0]\n",
    "        decay_steps = int((total_batch/batch_size)/4)\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            lr, decay_steps, t_mul=2.0, m_mul=1.0, alpha=0.0,\n",
    "            name=None\n",
    "        )\n",
    "        opt = optimizers.Adam(learning_rate=lr_schedule)\n",
    "        self.model.compile(loss = \"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "        if stop == True:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2, callbacks=[callback])\n",
    "        else:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "\n",
    "        return history\n",
    "\n",
    "    def search(self, lr, data_x, data_y):\n",
    "\n",
    "        lr_candidate = np.arange(lr[0], lr[1], lr[2])\n",
    "\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        for lr in lr_candidate:\n",
    "            history = self.train_model(10**(lr), 1, 32, False, data_x, data_y)\n",
    "            train_acc = history.history[\"accuracy\"]\n",
    "            val_acc = history.history[\"val_accuracy\"]\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        return train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net_3:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        pass\n",
    "\n",
    "    def init_network(self):\n",
    "        model = Sequential()\n",
    "        model.add(Conv2D(64, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(128, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Conv2D(256, kernel_size = 3, padding=\"same\", strides=(2,1)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(MaxPooling2D(pool_size = (2,2), strides = (2,2)))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1024))\n",
    "        model.add(Dropout(0.5))\n",
    "        model.add(Dense(26))\n",
    "        model.add(Activation(\"softmax\"))\n",
    "\n",
    "        self.model = model\n",
    "    \n",
    "        return model\n",
    "\n",
    "    def train_model(self, lr, epoch, batch_size, stop, data_x, data_y):\n",
    "        print(f\"lr : {lr}\")\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "\n",
    "        callback = tf.keras.callbacks.EarlyStopping( monitor='val_loss', min_delta=0, patience=100, \n",
    "        verbose=0, mode='auto', baseline=None, restore_best_weights=False)\n",
    "\n",
    "        total_batch = data_x.shape[0]\n",
    "        decay_steps = int((total_batch/batch_size)/4)\n",
    "\n",
    "        lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
    "            lr, decay_steps, t_mul=2.0, m_mul=1.0, alpha=0.0,\n",
    "            name=None\n",
    "        )\n",
    "        opt = optimizers.Adam(learning_rate=lr_schedule)\n",
    "        self.model.compile(loss = \"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "    \n",
    "        if stop == True:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2, callbacks=[callback])\n",
    "        else:\n",
    "            history = self.model.fit(data_x, data_y, epochs=epoch, batch_size=batch_size, validation_split=0.2)\n",
    "\n",
    "\n",
    "        return history\n",
    "\n",
    "    def search(self, lr, data_x, data_y):\n",
    "\n",
    "        lr_candidate = np.arange(lr[0], lr[1], lr[2])\n",
    "\n",
    "        train_accs = []\n",
    "        val_accs = []\n",
    "        for lr in lr_candidate:\n",
    "            history = self.train_model(10**(lr), 1, 32, False, data_x, data_y)\n",
    "            train_acc = history.history[\"accuracy\"]\n",
    "            val_acc = history.history[\"val_accuracy\"]\n",
    "            train_accs.append(train_acc)\n",
    "            val_accs.append(val_acc)\n",
    "\n",
    "        return train_accs, val_accs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x, test_x, data_y, test_y = load_data_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x212a48cea08>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net_2()\n",
    "model.init_network()\n",
    "#acc, val_acc = model.search((-3.5, -2.9, 0.1), data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr : 0.0001\n",
      "Epoch 1/16\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000212A49A0438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x00000212A49A0438> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "51/51 [==============================] - ETA: 0s - loss: 3.5030 - accuracy: 0.2201WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000212A4C5B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x00000212A4C5B048> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "51/51 [==============================] - 25s 469ms/step - loss: 3.5030 - accuracy: 0.2201 - val_loss: 5.6291 - val_accuracy: 0.0968\n",
      "Epoch 2/16\n",
      "51/51 [==============================] - 23s 444ms/step - loss: 0.7345 - accuracy: 0.8570 - val_loss: 3.5885 - val_accuracy: 0.1290\n",
      "Epoch 3/16\n",
      "51/51 [==============================] - 22s 434ms/step - loss: 0.2773 - accuracy: 0.9658 - val_loss: 2.8945 - val_accuracy: 0.2109\n",
      "Epoch 4/16\n",
      "51/51 [==============================] - 23s 442ms/step - loss: 0.0638 - accuracy: 0.9988 - val_loss: 1.9236 - val_accuracy: 0.4342\n",
      "Epoch 5/16\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.0433 - accuracy: 1.0000 - val_loss: 1.5109 - val_accuracy: 0.5707\n",
      "Epoch 6/16\n",
      "51/51 [==============================] - 23s 443ms/step - loss: 0.0284 - accuracy: 1.0000 - val_loss: 1.1926 - val_accuracy: 0.6576\n",
      "Epoch 7/16\n",
      "51/51 [==============================] - 23s 449ms/step - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.0847 - val_accuracy: 0.6749\n",
      "Epoch 8/16\n",
      "51/51 [==============================] - 23s 442ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 1.0653 - val_accuracy: 0.6973\n",
      "Epoch 9/16\n",
      "51/51 [==============================] - 23s 444ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.0549 - val_accuracy: 0.7022\n",
      "Epoch 10/16\n",
      "51/51 [==============================] - 23s 446ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.0569 - val_accuracy: 0.7022\n",
      "Epoch 11/16\n",
      "51/51 [==============================] - 23s 443ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.0304 - val_accuracy: 0.7072\n",
      "Epoch 12/16\n",
      "51/51 [==============================] - 22s 441ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.0411 - val_accuracy: 0.7097\n",
      "Epoch 13/16\n",
      "51/51 [==============================] - 22s 441ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.0270 - val_accuracy: 0.7221\n",
      "Epoch 14/16\n",
      "51/51 [==============================] - 23s 442ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 1.0173 - val_accuracy: 0.7146\n",
      "Epoch 15/16\n",
      "51/51 [==============================] - 23s 448ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 1.0201 - val_accuracy: 0.7122\n",
      "Epoch 16/16\n",
      "51/51 [==============================] - 23s 445ms/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 1.0164 - val_accuracy: 0.7146\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x212a49b0f48>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_model(10**(-4), 16, 32, True, data_x, data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000212A48D8798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x00000212A48D8798> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "pred=model.model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7923076923076923"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6464646464646465"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975369458128079"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7807692307692308"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6141414141414141"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975369458128079"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(np.argmax(test_y,axis=1),np.argmax(pred,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
